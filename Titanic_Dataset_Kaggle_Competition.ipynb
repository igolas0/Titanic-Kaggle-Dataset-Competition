{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bee3bf9",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bec5e0",
   "metadata": {},
   "source": [
    "The Titanic Kaggle Competition dataset is a popular dataset used for data analysis and machine learning projects. The dataset contains information about passengers aboard the Titanic, including their age, gender, ticket class, and whether they survived the sinking of the ship or not.\n",
    "\n",
    "Here's a brief overview of the dataset:\n",
    "\n",
    "The dataset contains information on 891 passengers on the Titanic, out of a total of 2224 passengers and crew members.\n",
    "\n",
    "The dataset contains 12 columns:\n",
    "\n",
    "        PassengerId: Unique identifier for each passenger\n",
    "        Survived: Whether the passenger survived or not (0 = No, 1 = Yes)\n",
    "        Pclass: Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)\n",
    "        Name: Passenger's name\n",
    "        Sex: Passenger's sex\n",
    "        Age: Passenger's age in years\n",
    "        SibSp: Number of siblings/spouses aboard the Titanic\n",
    "        Parch: Number of parents/children aboard the Titanic\n",
    "        Ticket: Ticket number\n",
    "        Fare: Passenger fare\n",
    "        Cabin: Cabin number\n",
    "        Embarked: Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296d012c",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8fa19c",
   "metadata": {},
   "source": [
    "Downloading the data from https://homl.info/titanic.tgz and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "127571c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "def load_titanic_data():\n",
    "    tarball_path = Path(\"datasets/titanic.tgz\")\n",
    "    if not tarball_path.is_file():\n",
    "        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n",
    "        url = \"https://homl.info/titanic.tgz\"\n",
    "        urllib.request.urlretrieve(url, tarball_path)\n",
    "        with tarfile.open(tarball_path) as titanic_tarball:\n",
    "            titanic_tarball.extractall(path=\"datasets\")\n",
    "    return pd.read_csv(Path(\"datasets/titanic/train.csv\"))\n",
    "\n",
    "titanic = load_titanic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f67229",
   "metadata": {},
   "source": [
    "# Take a Quick Look at the Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bfc319e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3d1b993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d1d1d",
   "metadata": {},
   "source": [
    "The second colum contains our labels aka target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9815757b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b849d8a5",
   "metadata": {},
   "source": [
    "We notice that 65% of the passengers are males VS only 35% female. We will take this into account later by separating a stratified test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e98b66",
   "metadata": {},
   "source": [
    "We might discard PassengerId, Name and Ticket information, since we doubt it will be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32c1aecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B96 B98        4\n",
       "G6             4\n",
       "C23 C25 C27    4\n",
       "C22 C26        3\n",
       "F33            3\n",
       "              ..\n",
       "E34            1\n",
       "C7             1\n",
       "C54            1\n",
       "E36            1\n",
       "C148           1\n",
       "Name: Cabin, Length: 147, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic[\"Cabin\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8252352",
   "metadata": {},
   "source": [
    "The \"Cabin\" input feature might need a little more thought to determine if it will serves as well in order to infer our predictions. One option would be to replace this category with a binary encoder (1 = cabin booked / known and 0 = cabin not booked or unknown). Another option would be using only the first letter of the cabin and using a categorical encoder. To get a first prototype relatively fast up and running we might choose to ignore this column at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f903de3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d6f5b3",
   "metadata": {},
   "source": [
    "The two missing values at colum \"Embarked\" will be replaced with the most common class (namely the S class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ee1b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699113</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526507</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699113    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526507    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.416700    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72a4660",
   "metadata": {},
   "source": [
    "There are over two hundred missing values for the category \"Age\". During the preprocessing step we will be replacing the missing values with the median of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40973333",
   "metadata": {},
   "source": [
    "Now we will be dropping the columns \"PassengerID\", \"Name\", \"Ticket\" and \"Cabin\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aa99346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S\n",
       "3         1       1  female  35.0      1      0  53.1000        S\n",
       "4         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_preprocessed = titanic.drop(columns=['PassengerId','Name','Ticket', 'Cabin'])\n",
    "\n",
    "titanic_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89b3c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# extra code – the next 5 lines define the default font sizes\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "\n",
    "titanic_preprocessed.hist(bins=50, figsize=(12, 8))\n",
    "#save_fig(\"attribute_histogram_plots\")  # extra code\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7d94e8",
   "metadata": {},
   "source": [
    "The features age, SibSp, Parch and Fare are all skewed right. They extend much farther to the right of the median than to the left. This might cause some machine learning algorithms to have trouble detecting patterns. Later we will transform these attributes to have more symmetrical and bell-shaped distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df77145",
   "metadata": {},
   "source": [
    "# Create a Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74792cca",
   "metadata": {},
   "source": [
    "Before we dig deeper into the data now it is a good time to separate the labels an create a test set. Since there is a gender imbalance we choose to create a stratified split and separate 20% of the data with the same gender percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a885f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "strat_train_set, strat_test_set = train_test_split(\n",
    "    titanic_preprocessed, test_size=0.2, stratify=titanic_preprocessed[\"Sex\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37bb7e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      116\n",
       "female     63\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_test_set[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed545425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      461\n",
       "female    251\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c98e4f",
   "metadata": {},
   "source": [
    "As we can observe the gender ratio in both train and test sets are kept by using the stratified split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6b2fb",
   "metadata": {},
   "source": [
    "# Explore and visualize the data to get insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57960ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dc1ad4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Plot a bar chart of passenger survival by sex\n",
    "sns.barplot(data=titanic, x='Sex', y='Survived')\n",
    "plt.title('Survival Rate by Sex')\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef2cf2",
   "metadata": {},
   "source": [
    "As we can observe the gender has a big impact in the survival rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18c6593e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a boxplot of passenger fares by ticket class\n",
    "sns.boxplot(data=titanic, x='Pclass', y='Fare')\n",
    "plt.title('Fare Distribution by Ticket Class')\n",
    "plt.xlabel('Ticket Class')\n",
    "plt.ylabel('Fare')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb739df",
   "metadata": {},
   "source": [
    "As expected ticket class and passenger fare are fairly closely correlated with some outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60aa288",
   "metadata": {},
   "source": [
    "Let's now plot Survival Rate for each ticket class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cecd80fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a bar chart of passenger survival by ticket class\n",
    "sns.barplot(data=titanic, x='Pclass', y='Survived')\n",
    "plt.title('Survival Rate by Ticket Class')\n",
    "plt.xlabel('Ticket Class')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229abbd",
   "metadata": {},
   "source": [
    "Next let's plot the \"Embarked\" class against survival rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a08188b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a bar chart of passenger survival by Embarked port\n",
    "sns.barplot(data=titanic, x='Embarked', y='Survived')\n",
    "plt.title('Survival Rate by Embarked Port')\n",
    "plt.xlabel('Embarked Port')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1eb681",
   "metadata": {},
   "source": [
    "We do see a clear correlation with passengers embarked at Chesbourg showing the highest survival rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bad200",
   "metadata": {},
   "source": [
    "Lets create new age categories and plot the survival rate per age category.\n",
    "0 - 15 Babys, toddlers and small kids\n",
    "8 - 15 kids and teens\n",
    "16 - 30 early adult\n",
    "31- 60 adult\n",
    "61+ senile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e391eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "titanic[\"age_cat\"] = pd.cut(titanic[\"Age\"],\n",
    "                           bins=[0, 7.5, 15.5, 30.5, 60.5, np.inf],\n",
    "                           labels = [1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfea616e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a bar chart of passenger survival by age category\n",
    "sns.barplot(data=titanic, x='age_cat', y='Survived')\n",
    "plt.title('Survival Rate by Age Category')\n",
    "plt.xlabel('Age Category')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2bbda5",
   "metadata": {},
   "source": [
    "From plotting the survival rate by age categories we do see a correlation. It seems infants and toddlers do have a higher survival rate while the very old do show a decrease of the survival rate compared to other adults."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9190c5e3",
   "metadata": {},
   "source": [
    "Next we will assess if creating categories for the feature SibSp could be valuable. First we take a look at how values are distributed for this feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d85fadde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    477\n",
       "1    171\n",
       "2     25\n",
       "4     16\n",
       "3     13\n",
       "8      5\n",
       "5      5\n",
       "Name: SibSp, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic[\"SibSp\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9666368",
   "metadata": {},
   "source": [
    "Based on the values distribution we opt for the following categories for the SibSp (number of siblings/spouses) feature:\n",
    " 1. Passengers with 0 siblings/spouses.\n",
    " 2. Passengers with 1 sibling/spouse.\n",
    " 3. Passengers with 2 or 3 siblings/spouse.\n",
    " 4. Passengers with 4 or more siblings/spouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46b2f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"SibSp_cat\"] = pd.cut(titanic[\"SibSp\"],\n",
    "                           bins=[-1, 0.5, 1.5, 3.5, np.inf],\n",
    "                           labels = [1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "227f5eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a bar chart of passenger survival by SibSp category\n",
    "sns.barplot(data=titanic, x='SibSp_cat', y='Survived')\n",
    "plt.title('Survival Rate by SibSp Category')\n",
    "plt.xlabel('SibSp Category')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff01c4b0",
   "metadata": {},
   "source": [
    "We do observe some correlation with the category with 1 sibling/spouse scoring the highest survival rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b92638",
   "metadata": {},
   "source": [
    "Next we do the same for the Parch feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "600373cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    543\n",
       "1     99\n",
       "2     58\n",
       "5      4\n",
       "4      4\n",
       "3      3\n",
       "6      1\n",
       "Name: Parch, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic[\"Parch\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3265cc0d",
   "metadata": {},
   "source": [
    "Based on the observed value distribution we opt to plot the following categories for the Parch feature (number of parents/children aboard the Titanic).\n",
    " 1. Passengers with 0 parents/children.\n",
    " 2. Passengers with 1 parents/children.\n",
    " 3. Passengers with 2 parents/children.\n",
    " 4. Passengers with 3 or more parents/children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5d156c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Parch_cat\"] = pd.cut(titanic[\"Parch\"],\n",
    "                           bins=[-1, 0.5, 1.5, 2.5, np.inf],\n",
    "                           labels = [1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74995c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a bar chart of passenger survival by Parch category\n",
    "sns.barplot(data=titanic, x='Parch_cat', y='Survived')\n",
    "plt.title('Survival Rate by Parch Category')\n",
    "plt.xlabel('Parch Category')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d981a15",
   "metadata": {},
   "source": [
    "Based on the above chart it might make sense to joint categories 2 and 3 since survival rate is similar. Category number 4 shows a high std deviation but since only 12 passengers represent this category it probably does not make sense to create more categories for further differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07cac0f",
   "metadata": {},
   "source": [
    "# Looking for correlations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d25ddc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = titanic.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b6f3943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    1.000000\n",
       "Fare        0.248255\n",
       "Parch       0.059276\n",
       "SibSp      -0.045019\n",
       "Age        -0.075542\n",
       "Pclass     -0.314577\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix[\"Survived\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8a29cb",
   "metadata": {},
   "source": [
    "It seems especially the passenger fare and ticket class show the strongest correlation with the survival rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03925f7",
   "metadata": {},
   "source": [
    "Let's try to experiment with a new feature family which is the sum out of 'SibSp' and 'Parch' and look again at the correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "619b269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"family\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b137fc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    1.000000\n",
       "Fare        0.248255\n",
       "Parch       0.059276\n",
       "family     -0.001468\n",
       "SibSp      -0.045019\n",
       "Age        -0.075542\n",
       "Pclass     -0.314577\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = titanic.corr()\n",
    "corr_matrix[\"Survived\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a11370",
   "metadata": {},
   "source": [
    "It does not seem like it will improve correlation with the Survived target category, hence we won't be using it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27174485",
   "metadata": {},
   "source": [
    "# Prepare the Data for Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60c0c51",
   "metadata": {},
   "source": [
    "Let's revert to the original training set and separate the target (note that strat_train_set.drop() creates a copy of strat_train_set without the column, it doesn't actually modify strat_train_set itself, unless you pass inplace=True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a32e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = strat_train_set.drop(\"Survived\", axis=1, inplace=False)\n",
    "titanic_labels = strat_train_set[\"Survived\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd3543a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "788       3    male   1.0      1      2  20.5750        S\n",
       "347       3  female   NaN      1      0  16.1000        S\n",
       "629       3    male   NaN      0      0   7.7333        Q\n",
       "734       2    male  23.0      0      0  13.0000        S\n",
       "106       3  female  21.0      0      0   7.6500        S"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bca567a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 788 to 261\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    712 non-null    int64  \n",
      " 1   Sex       712 non-null    object \n",
      " 2   Age       578 non-null    float64\n",
      " 3   SibSp     712 non-null    int64  \n",
      " 4   Parch     712 non-null    int64  \n",
      " 5   Fare      712 non-null    float64\n",
      " 6   Embarked  710 non-null    object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 44.5+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd75863d",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfb315c",
   "metadata": {},
   "source": [
    "For the age class we will be replacing missing values with the median and transforming the features with a logarithmic transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22bda4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp = SimpleImputer(strategy='median')\n",
    "\n",
    "titanic_num = titanic.select_dtypes(include=[np.number])\n",
    "\n",
    "X = imp.fit_transform(titanic_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3f60d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num_clean = pd.DataFrame(X, columns=titanic_num.columns,\n",
    "                          index=titanic_num.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "320fa2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 788 to 261\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Pclass  712 non-null    float64\n",
      " 1   Age     712 non-null    float64\n",
      " 2   SibSp   712 non-null    float64\n",
      " 3   Parch   712 non-null    float64\n",
      " 4   Fare    712 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 33.4 KB\n"
     ]
    }
   ],
   "source": [
    "housing_num_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b401ec1",
   "metadata": {},
   "source": [
    "### Age feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6737423",
   "metadata": {},
   "source": [
    "Let's see how the log of the age plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0cd26e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3), sharey=True)\n",
    "titanic[\"Age\"].hist(ax=axs[0], bins=50)\n",
    "titanic[\"Age\"].apply(np.log).hist(ax=axs[1], bins=50)\n",
    "axs[0].set_xlabel(\"Age\")\n",
    "axs[1].set_xlabel(\"Log of Age\")\n",
    "axs[0].set_ylabel(\"Number of passengers\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bec215",
   "metadata": {},
   "source": [
    "For the age feature we will be transforming this feature by the log() to reduce the heavy tail and then feature scaling with the StandardScaler() function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29285dd9",
   "metadata": {},
   "source": [
    "Later it seems that without applying the log() on the Age feature the model performs slightly better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd4807a",
   "metadata": {},
   "source": [
    "### Fare feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86f17a2",
   "metadata": {},
   "source": [
    "I think the fare feature codes for similar information as the ticket class and has lower correlation than the ticket class, hence we opt to drop this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0fefc5",
   "metadata": {},
   "source": [
    "### Transformation pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6021264",
   "metadata": {},
   "source": [
    "We will be using a transformation pipeline to apply on all of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6ca3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "cat_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    \n",
    "\n",
    "default_num_pipeline = make_pipeline(SimpleImputer(strategy=\"median\"),\n",
    "                                     StandardScaler())\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "        (\"num\", default_num_pipeline, [\"Fare\", \"Age\"]),\n",
    "    ],\n",
    "    remainder=cat_pipeline)  # columns remaining: Embarked, Sex and Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "117ba5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 24)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_prepared = preprocessing.fit_transform(titanic)\n",
    "titanic_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3af9fcfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['num__Fare', 'num__Age', 'remainder__Pclass_1',\n",
       "       'remainder__Pclass_2', 'remainder__Pclass_3',\n",
       "       'remainder__Sex_female', 'remainder__Sex_male',\n",
       "       'remainder__SibSp_0', 'remainder__SibSp_1', 'remainder__SibSp_2',\n",
       "       'remainder__SibSp_3', 'remainder__SibSp_4', 'remainder__SibSp_5',\n",
       "       'remainder__SibSp_8', 'remainder__Parch_0', 'remainder__Parch_1',\n",
       "       'remainder__Parch_2', 'remainder__Parch_3', 'remainder__Parch_4',\n",
       "       'remainder__Parch_5', 'remainder__Parch_6',\n",
       "       'remainder__Embarked_C', 'remainder__Embarked_Q',\n",
       "       'remainder__Embarked_S'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa70d8f",
   "metadata": {},
   "source": [
    "# Select and Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a9e576",
   "metadata": {},
   "source": [
    "### RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6ec1eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                              SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                             (&#x27;onehotencoder&#x27;,\n",
       "                                                              OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                   transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;standardscaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;Fare&#x27;, &#x27;Age&#x27;])])),\n",
       "                (&#x27;random_forest&#x27;, RandomForestClassifier(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                              SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                             (&#x27;onehotencoder&#x27;,\n",
       "                                                              OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                   transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;standardscaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;Fare&#x27;, &#x27;Age&#x27;])])),\n",
       "                (&#x27;random_forest&#x27;, RandomForestClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                             SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                            (&#x27;onehotencoder&#x27;,\n",
       "                                             OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                  transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;Fare&#x27;, &#x27;Age&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Fare&#x27;, &#x27;Age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;, &#x27;Embarked&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(remainder=Pipeline(steps=[('simpleimputer',\n",
       "                                                              SimpleImputer(strategy='most_frequent')),\n",
       "                                                             ('onehotencoder',\n",
       "                                                              OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(steps=[('simpleimputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('standardscaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Fare', 'Age'])])),\n",
       "                ('random_forest', RandomForestClassifier(random_state=42))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "full_pipeline_forest = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"random_forest\", RandomForestClassifier(random_state=42)),\n",
    "])\n",
    "\n",
    "\n",
    "y_probas_forest = cross_val_predict(full_pipeline_forest, titanic, titanic_labels, cv=5,\n",
    "                                   method=\"predict_proba\")\n",
    "\n",
    "full_pipeline_forest.fit(titanic, titanic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3771acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = y_probas_forest[:,1] >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d65f7b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the model: 0.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(titanic_labels, y_pred_train)\n",
    "print(\"Accuracy score of the model: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9af6b9",
   "metadata": {},
   "source": [
    "Now let's take a look at the feature importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c43f230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25, 0.25, 0.03, 0.01, 0.05, 0.14, 0.14, 0.02, 0.02, 0.01, 0.01,\n",
       "       0.01, 0.  , 0.  , 0.02, 0.01, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01,\n",
       "       0.01, 0.02])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = full_pipeline_forest[\"random_forest\"].feature_importances_\n",
    "feature_importances.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b3cba82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.25099543574785, 'num__Age'),\n",
       " (0.249042288704961, 'num__Fare'),\n",
       " (0.14158646059118368, 'remainder__Sex_female'),\n",
       " (0.13504249228655105, 'remainder__Sex_male'),\n",
       " (0.048408354746462476, 'remainder__Pclass_3'),\n",
       " (0.025914873024876477, 'remainder__Pclass_1'),\n",
       " (0.018027075720899413, 'remainder__Parch_0'),\n",
       " (0.016900574595628024, 'remainder__SibSp_1'),\n",
       " (0.015764562746199418, 'remainder__Embarked_S'),\n",
       " (0.015397035765121886, 'remainder__SibSp_0'),\n",
       " (0.013814287506814567, 'remainder__Embarked_C'),\n",
       " (0.01204356018001251, 'remainder__Parch_1'),\n",
       " (0.01141800027816974, 'remainder__Pclass_2'),\n",
       " (0.010229298154202525, 'remainder__Embarked_Q'),\n",
       " (0.008768860773290043, 'remainder__Parch_2'),\n",
       " (0.00662024103387825, 'remainder__SibSp_3'),\n",
       " (0.0053782509775815055, 'remainder__SibSp_2'),\n",
       " (0.005052723683928177, 'remainder__SibSp_4'),\n",
       " (0.0024072188482197657, 'remainder__SibSp_8'),\n",
       " (0.0023556348230743436, 'remainder__Parch_5'),\n",
       " (0.0020675775519995595, 'remainder__Parch_4'),\n",
       " (0.001566295471194734, 'remainder__SibSp_5'),\n",
       " (0.000839456950794264, 'remainder__Parch_3'),\n",
       " (0.00035943983710653125, 'remainder__Parch_6')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(feature_importances,\n",
    "           preprocessing.get_feature_names_out()),\n",
    "           reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee622de4",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d1c12886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8117977528089888"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "full_pipeline_lr = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"logistic_clf\", LogisticRegression(random_state=42)),\n",
    "])\n",
    "\n",
    "lr_clf = full_pipeline_lr.fit(titanic, titanic_labels)\n",
    "\n",
    "lr_clf.score(titanic, titanic_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75a8fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = lr_clf.predict(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5cd9e602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the model: 0.81\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(titanic_labels, y_pred_train)\n",
    "print(\"Accuracy score of the model: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df041c28",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "694a3ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8356741573033708"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "full_pipeline_svc = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"svc_clf\", svm.SVC(random_state=42)),\n",
    "])\n",
    "\n",
    "svc_clf = full_pipeline_svc.fit(titanic, titanic_labels)\n",
    "\n",
    "svc_clf.score(titanic, titanic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26230366",
   "metadata": {},
   "source": [
    "### K-Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98b347c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8595505617977528"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "full_pipeline_kneigh = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"kneigh_clf\", KNeighborsClassifier(n_neighbors=4)),\n",
    "])\n",
    "\n",
    "neigh_clf = full_pipeline_kneigh.fit(titanic, titanic_labels)\n",
    "\n",
    "neigh_clf.score(titanic, titanic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a25abd",
   "metadata": {},
   "source": [
    "# Fine-Tuning the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b104b4",
   "metadata": {},
   "source": [
    "### Fine-Tuning RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96ceb7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3111; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3111; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2000; total time=   2.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2222; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=3111; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=3111; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2000; total time=   1.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=4000; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2888; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3111; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2888; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2888; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   1.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2000; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2000; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2222; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2222; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=3111; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=3111; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=4000; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2888; total time=   3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3111; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2888; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2000; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=3111; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=3111; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=3111; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=4000; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2888; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3111; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2888; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2888; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2000; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=3111; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=3111; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=3111; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=4000; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=4000; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=3111; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2000; total time=   1.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2000; total time=   1.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3777; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2222; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2222; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3333; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=2444; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   1.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=2888; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=3111; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=3111; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2000; total time=   1.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2000; total time=   2.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2222; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2222; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3333; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=2444; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=2888; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2888; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=3111; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3777; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3777; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2222; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3333; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=2888; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=2888; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=3111; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2000; total time=   1.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3777; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3777; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2222; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2222; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3333; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3333; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=2444; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=2888; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2000; total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2000; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2444; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2444; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2666; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3777; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3111; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3111; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2444; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2444; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2666; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3777; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3777; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3111; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2000; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2444; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2666; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3777; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3111; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3111; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2000; total time=   2.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2666; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2666; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=2444; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3777; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3111; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   1.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   4.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3111; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=2888; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   3.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3111; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=2888; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=2888; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   5.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=4000; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2000; total time=   1.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2000; total time=   1.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3111; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   4.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3111; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3111; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=2888; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   2.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   5.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   5.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=2222; total time=   2.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=4000; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=4000; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2000; total time=   1.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3111; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2222; total time=   3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3111; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=2888; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   6.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   5.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=4000; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2888; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3111; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3111; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   4.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2222; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   5.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=2222; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   5.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=4000; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2000; total time=   1.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2000; total time=   1.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3111; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   5.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2222; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   4.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   4.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2222; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   4.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   4.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2000; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=4000; total time=   4.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3333; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2222; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   4.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   4.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=2888; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3333; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2888; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2444; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2444; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2222; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2000; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=4000; total time=   5.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3333; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2222; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   6.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   4.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=2888; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=2888; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3333; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2888; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2888; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2444; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=2000; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=3777; total time=   4.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   4.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2444; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2000; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=4000; total time=   5.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3333; total time=   4.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3333; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2222; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   5.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=2888; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3333; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3333; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2444; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=2444; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=2000; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=2000; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=3777; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=3777; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2000; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=4000; total time=   5.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=4000; total time=   5.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   5.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=3333; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   6.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   4.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=2888; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=3333; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2888; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2888; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=15, random_forest__n_estimators=2000; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=3777; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=3777; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=3333; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=2222; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=3111; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   5.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   4.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=3333; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=3333; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=2222; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=3111; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=2222; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2888; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   4.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=2666; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   4.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=3333; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=2222; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=2222; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=3111; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=2666; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=4000; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=3333; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=3555; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=17, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   4.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   4.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2444; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=2000; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=4000; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=11, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=3333; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=25, random_forest__n_estimators=2222; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=3111; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=3111; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   1.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=2444; total time=   2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=2222; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3555; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   1.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=15, random_forest__n_estimators=2222; total time=   2.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2888; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=3111; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2222; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2222; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=2888; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=3333; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2888; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3333; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=5, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   1.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=15, random_forest__n_estimators=2222; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=15, random_forest__n_estimators=2222; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2888; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=3111; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=3111; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2222; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=3333; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=3333; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3333; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=4000; total time=   4.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3777; total time=   4.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   1.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=2000; total time=   1.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=None, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=20, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=15, random_forest__n_estimators=2222; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=3111; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=2222; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=2222; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2222; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   4.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=3333; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2888; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2888; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3333; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   4.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=4000; total time=   4.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2444; total time=   3.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                           SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                          (&#x27;onehotencoder&#x27;,\n",
       "                                                                                           OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                transformers=[(&#x27;num&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                                SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                                               (&#x27;standardscaler&#x27;,\n",
       "                                                                                                StandardScaler()...\n",
       "                   param_distributions={&#x27;random_forest__bootstrap&#x27;: [True,\n",
       "                                                                     False],\n",
       "                                        &#x27;random_forest__max_depth&#x27;: [5, 6, 8, 9,\n",
       "                                                                     11, 12, 14,\n",
       "                                                                     15, 17, 18,\n",
       "                                                                     20, None],\n",
       "                                        &#x27;random_forest__max_features&#x27;: [&#x27;log2&#x27;,\n",
       "                                                                        &#x27;sqrt&#x27;],\n",
       "                                        &#x27;random_forest__min_samples_leaf&#x27;: [1,\n",
       "                                                                            2,\n",
       "                                                                            3,\n",
       "                                                                            4,\n",
       "                                                                            5],\n",
       "                                        &#x27;random_forest__min_samples_split&#x27;: [10,\n",
       "                                                                             15,\n",
       "                                                                             20,\n",
       "                                                                             25,\n",
       "                                                                             30],\n",
       "                                        &#x27;random_forest__n_estimators&#x27;: [2000,\n",
       "                                                                        2222,\n",
       "                                                                        2444,\n",
       "                                                                        2666,\n",
       "                                                                        2888,\n",
       "                                                                        3111,\n",
       "                                                                        3333,\n",
       "                                                                        3555,\n",
       "                                                                        3777,\n",
       "                                                                        4000]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                           SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                          (&#x27;onehotencoder&#x27;,\n",
       "                                                                                           OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                transformers=[(&#x27;num&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                                SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                                               (&#x27;standardscaler&#x27;,\n",
       "                                                                                                StandardScaler()...\n",
       "                   param_distributions={&#x27;random_forest__bootstrap&#x27;: [True,\n",
       "                                                                     False],\n",
       "                                        &#x27;random_forest__max_depth&#x27;: [5, 6, 8, 9,\n",
       "                                                                     11, 12, 14,\n",
       "                                                                     15, 17, 18,\n",
       "                                                                     20, None],\n",
       "                                        &#x27;random_forest__max_features&#x27;: [&#x27;log2&#x27;,\n",
       "                                                                        &#x27;sqrt&#x27;],\n",
       "                                        &#x27;random_forest__min_samples_leaf&#x27;: [1,\n",
       "                                                                            2,\n",
       "                                                                            3,\n",
       "                                                                            4,\n",
       "                                                                            5],\n",
       "                                        &#x27;random_forest__min_samples_split&#x27;: [10,\n",
       "                                                                             15,\n",
       "                                                                             20,\n",
       "                                                                             25,\n",
       "                                                                             30],\n",
       "                                        &#x27;random_forest__n_estimators&#x27;: [2000,\n",
       "                                                                        2222,\n",
       "                                                                        2444,\n",
       "                                                                        2666,\n",
       "                                                                        2888,\n",
       "                                                                        3111,\n",
       "                                                                        3333,\n",
       "                                                                        3555,\n",
       "                                                                        3777,\n",
       "                                                                        4000]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                              SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                             (&#x27;onehotencoder&#x27;,\n",
       "                                                              OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                   transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;standardscaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;Fare&#x27;, &#x27;Age&#x27;])])),\n",
       "                (&#x27;random_forest&#x27;, RandomForestClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                             SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                            (&#x27;onehotencoder&#x27;,\n",
       "                                             OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                  transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;Fare&#x27;, &#x27;Age&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Fare&#x27;, &#x27;Age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;, &#x27;Embarked&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('preprocessing',\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[('simpleimputer',\n",
       "                                                                                           SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                          ('onehotencoder',\n",
       "                                                                                           OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                transformers=[('num',\n",
       "                                                                               Pipeline(steps=[('simpleimputer',\n",
       "                                                                                                SimpleImputer(strategy='median')),\n",
       "                                                                                               ('standardscaler',\n",
       "                                                                                                StandardScaler()...\n",
       "                   param_distributions={'random_forest__bootstrap': [True,\n",
       "                                                                     False],\n",
       "                                        'random_forest__max_depth': [5, 6, 8, 9,\n",
       "                                                                     11, 12, 14,\n",
       "                                                                     15, 17, 18,\n",
       "                                                                     20, None],\n",
       "                                        'random_forest__max_features': ['log2',\n",
       "                                                                        'sqrt'],\n",
       "                                        'random_forest__min_samples_leaf': [1,\n",
       "                                                                            2,\n",
       "                                                                            3,\n",
       "                                                                            4,\n",
       "                                                                            5],\n",
       "                                        'random_forest__min_samples_split': [10,\n",
       "                                                                             15,\n",
       "                                                                             20,\n",
       "                                                                             25,\n",
       "                                                                             30],\n",
       "                                        'random_forest__n_estimators': [2000,\n",
       "                                                                        2222,\n",
       "                                                                        2444,\n",
       "                                                                        2666,\n",
       "                                                                        2888,\n",
       "                                                                        3111,\n",
       "                                                                        3333,\n",
       "                                                                        3555,\n",
       "                                                                        3777,\n",
       "                                                                        4000]},\n",
       "                   random_state=42, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the hyperparameter space\n",
    "n_estimators = [int(x) for x in np.linspace(start = 2000, stop = 4000, num = 10)]\n",
    "max_features = ['log2', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(5, 20, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [10, 15, 20, 25, 30]\n",
    "min_samples_leaf = [1, 2, 3, 4, 5]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {\n",
    "    'random_forest__n_estimators': n_estimators,\n",
    "    'random_forest__max_features': max_features,\n",
    "    'random_forest__max_depth': max_depth,\n",
    "    'random_forest__min_samples_split': min_samples_split,\n",
    "    'random_forest__min_samples_leaf': min_samples_leaf,\n",
    "    'random_forest__bootstrap': bootstrap\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate the random forest classifier\n",
    "full_pipeline_forest = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"random_forest\", RandomForestClassifier(random_state=42)),\n",
    "])\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    full_pipeline_forest, param_distributions=random_grid, n_iter=200, cv=5,\n",
    "    scoring='accuracy', random_state=42, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_random.fit(titanic, titanic_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ddd092ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_forest__n_estimators': 3777, 'random_forest__min_samples_split': 20, 'random_forest__min_samples_leaf': 3, 'random_forest__max_features': 'log2', 'random_forest__max_depth': 11, 'random_forest__bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters found\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7d033548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8665730337078652"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=2666; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   2.5s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2000; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   3.5s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=4000; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2444; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=2666; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.3s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2000; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2444; total time=   2.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=2666; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2444; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2000; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2000; total time=   2.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=15, random_forest__n_estimators=2222; total time=   2.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=12, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2888; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=10, random_forest__n_estimators=2888; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=3555; total time=   2.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=10, random_forest__n_estimators=3111; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=11, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=20, random_forest__n_estimators=2222; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=10, random_forest__n_estimators=3555; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=10, random_forest__n_estimators=2222; total time=   3.0s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=4000; total time=   4.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=15, random_forest__n_estimators=3555; total time=   4.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=8, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   4.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.7s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=20, random_forest__n_estimators=2666; total time=   2.3s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=1, random_forest__min_samples_split=25, random_forest__n_estimators=2888; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=4, random_forest__min_samples_split=30, random_forest__n_estimators=2222; total time=   2.4s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=9, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=25, random_forest__n_estimators=3777; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=9, random_forest__max_features=sqrt, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=3777; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=12, random_forest__max_features=log2, random_forest__min_samples_leaf=5, random_forest__min_samples_split=20, random_forest__n_estimators=3333; total time=   3.2s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2888; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3333; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3333; total time=   3.9s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=6, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=3777; total time=   3.1s\n",
      "[CV] END random_forest__bootstrap=False, random_forest__max_depth=8, random_forest__max_features=log2, random_forest__min_samples_leaf=3, random_forest__min_samples_split=15, random_forest__n_estimators=2666; total time=   2.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=20, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3333; total time=   3.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=4000; total time=   4.8s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=15, random_forest__max_features=sqrt, random_forest__min_samples_leaf=3, random_forest__min_samples_split=25, random_forest__n_estimators=4000; total time=   4.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=2666; total time=   3.4s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=log2, random_forest__min_samples_leaf=2, random_forest__min_samples_split=10, random_forest__n_estimators=2666; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.7s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=14, random_forest__max_features=log2, random_forest__min_samples_leaf=1, random_forest__min_samples_split=30, random_forest__n_estimators=3111; total time=   3.6s\n",
      "[CV] END random_forest__bootstrap=True, random_forest__max_depth=18, random_forest__max_features=sqrt, random_forest__min_samples_leaf=2, random_forest__min_samples_split=15, random_forest__n_estimators=2000; total time=   2.3s\n"
     ]
    }
   ],
   "source": [
    "rf_random.best_estimator_.score(titanic, titanic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650f9ef9",
   "metadata": {},
   "source": [
    "Best Random Forest Parameters found after 200 iter:\n",
    "\n",
    "{'random_forest__n_estimators': 2500, 'random_forest__min_samples_split': 20, 'random_forest__min_samples_leaf': 3, 'random_forest__max_features': 'sqrt', 'random_forest__max_depth': None, 'random_forest__bootstrap': False}\n",
    "\n",
    "Reached Accuracy of 86,9%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812ee94",
   "metadata": {},
   "source": [
    "### Fine-Tuning Logistic Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5b692b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 1800 is smaller than n_iter=5000. Running 1800 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1800 candidates, totalling 9000 fits\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1121, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1121, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1121, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1121, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1121, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1146, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1172, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1172, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1172, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1172, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1197, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1197, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1197, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1197, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1197, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1197, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1197, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1197, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1223, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1197, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1197, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1197, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1197, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1248, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1274, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=1300, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.4, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.5, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.6, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.7, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=258, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=288, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=294, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=0.8, logistic_regression__max_iter=300, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=10, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=15, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=21, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=27, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=33, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=39, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=45, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=51, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=57, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=63, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=69, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=75, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=81, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=86, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=92, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=98, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=104, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=110, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=116, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=122, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=128, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=134, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=140, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=146, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=sag; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=152, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=187, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=157, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=163, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=169, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=175, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=181, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=193, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=199, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=205, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=211, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=234, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=lbfgs; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=217, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=223, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=228, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=240, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=246, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=258, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=258, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=288, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=288, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=288, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=252, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=258, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=258, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=264, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=270, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=newton-cholesky; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=276, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=sag; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.1s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=282, logistic_regression__solver=saga; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=288, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=294, logistic_regression__solver=lbfgs; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=294, logistic_regression__solver=liblinear; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n",
      "[CV] END logistic_regression__C=1.0, logistic_regression__max_iter=294, logistic_regression__solver=newton-cg; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "1500 fits failed out of a total of 9000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1500 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 48, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got newton-cholesky.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.80336846 0.80899242 0.80899242 ...        nan 0.80617551 0.80617551]\n",
      "  warnings.warn(\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                           SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                          (&#x27;onehotencoder&#x27;,\n",
       "                                                                                           OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                transformers=[(&#x27;num&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                                SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                                               (&#x27;standardscaler&#x27;,\n",
       "                                                                                                StandardScaler()...\n",
       "                   param_distributions={&#x27;logistic_regression__C&#x27;: [0.4, 0.5,\n",
       "                                                                   0.6, 0.7,\n",
       "                                                                   0.8, 1.0],\n",
       "                                        &#x27;logistic_regression__max_iter&#x27;: [10,\n",
       "                                                                          15,\n",
       "                                                                          21,\n",
       "                                                                          27,\n",
       "                                                                          33,\n",
       "                                                                          39,\n",
       "                                                                          45,\n",
       "                                                                          51,\n",
       "                                                                          57,\n",
       "                                                                          63,\n",
       "                                                                          69,\n",
       "                                                                          75,\n",
       "                                                                          81,\n",
       "                                                                          86,\n",
       "                                                                          92,\n",
       "                                                                          98,\n",
       "                                                                          104,\n",
       "                                                                          110,\n",
       "                                                                          116,\n",
       "                                                                          122,\n",
       "                                                                          128,\n",
       "                                                                          134,\n",
       "                                                                          140,\n",
       "                                                                          146,\n",
       "                                                                          152,\n",
       "                                                                          157,\n",
       "                                                                          163,\n",
       "                                                                          169,\n",
       "                                                                          175,\n",
       "                                                                          181, ...],\n",
       "                                        &#x27;logistic_regression__solver&#x27;: [&#x27;lbfgs&#x27;,\n",
       "                                                                        &#x27;liblinear&#x27;,\n",
       "                                                                        &#x27;newton-cg&#x27;,\n",
       "                                                                        &#x27;newton-cholesky&#x27;,\n",
       "                                                                        &#x27;sag&#x27;,\n",
       "                                                                        &#x27;saga&#x27;]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-140\" type=\"checkbox\" ><label for=\"sk-estimator-id-140\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                           SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                          (&#x27;onehotencoder&#x27;,\n",
       "                                                                                           OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                transformers=[(&#x27;num&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                                SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                                               (&#x27;standardscaler&#x27;,\n",
       "                                                                                                StandardScaler()...\n",
       "                   param_distributions={&#x27;logistic_regression__C&#x27;: [0.4, 0.5,\n",
       "                                                                   0.6, 0.7,\n",
       "                                                                   0.8, 1.0],\n",
       "                                        &#x27;logistic_regression__max_iter&#x27;: [10,\n",
       "                                                                          15,\n",
       "                                                                          21,\n",
       "                                                                          27,\n",
       "                                                                          33,\n",
       "                                                                          39,\n",
       "                                                                          45,\n",
       "                                                                          51,\n",
       "                                                                          57,\n",
       "                                                                          63,\n",
       "                                                                          69,\n",
       "                                                                          75,\n",
       "                                                                          81,\n",
       "                                                                          86,\n",
       "                                                                          92,\n",
       "                                                                          98,\n",
       "                                                                          104,\n",
       "                                                                          110,\n",
       "                                                                          116,\n",
       "                                                                          122,\n",
       "                                                                          128,\n",
       "                                                                          134,\n",
       "                                                                          140,\n",
       "                                                                          146,\n",
       "                                                                          152,\n",
       "                                                                          157,\n",
       "                                                                          163,\n",
       "                                                                          169,\n",
       "                                                                          175,\n",
       "                                                                          181, ...],\n",
       "                                        &#x27;logistic_regression__solver&#x27;: [&#x27;lbfgs&#x27;,\n",
       "                                                                        &#x27;liblinear&#x27;,\n",
       "                                                                        &#x27;newton-cg&#x27;,\n",
       "                                                                        &#x27;newton-cholesky&#x27;,\n",
       "                                                                        &#x27;sag&#x27;,\n",
       "                                                                        &#x27;saga&#x27;]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-141\" type=\"checkbox\" ><label for=\"sk-estimator-id-141\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                              SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                             (&#x27;onehotencoder&#x27;,\n",
       "                                                              OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                   transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;standardscaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;Fare&#x27;, &#x27;Age&#x27;])])),\n",
       "                (&#x27;logistic_regression&#x27;, LogisticRegression(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-142\" type=\"checkbox\" ><label for=\"sk-estimator-id-142\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                             SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                            (&#x27;onehotencoder&#x27;,\n",
       "                                             OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                  transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;Fare&#x27;, &#x27;Age&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-143\" type=\"checkbox\" ><label for=\"sk-estimator-id-143\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Fare&#x27;, &#x27;Age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-144\" type=\"checkbox\" ><label for=\"sk-estimator-id-144\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-145\" type=\"checkbox\" ><label for=\"sk-estimator-id-145\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-146\" type=\"checkbox\" ><label for=\"sk-estimator-id-146\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;, &#x27;Embarked&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-147\" type=\"checkbox\" ><label for=\"sk-estimator-id-147\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-148\" type=\"checkbox\" ><label for=\"sk-estimator-id-148\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-149\" type=\"checkbox\" ><label for=\"sk-estimator-id-149\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('preprocessing',\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[('simpleimputer',\n",
       "                                                                                           SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                          ('onehotencoder',\n",
       "                                                                                           OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                transformers=[('num',\n",
       "                                                                               Pipeline(steps=[('simpleimputer',\n",
       "                                                                                                SimpleImputer(strategy='median')),\n",
       "                                                                                               ('standardscaler',\n",
       "                                                                                                StandardScaler()...\n",
       "                   param_distributions={'logistic_regression__C': [0.4, 0.5,\n",
       "                                                                   0.6, 0.7,\n",
       "                                                                   0.8, 1.0],\n",
       "                                        'logistic_regression__max_iter': [10,\n",
       "                                                                          15,\n",
       "                                                                          21,\n",
       "                                                                          27,\n",
       "                                                                          33,\n",
       "                                                                          39,\n",
       "                                                                          45,\n",
       "                                                                          51,\n",
       "                                                                          57,\n",
       "                                                                          63,\n",
       "                                                                          69,\n",
       "                                                                          75,\n",
       "                                                                          81,\n",
       "                                                                          86,\n",
       "                                                                          92,\n",
       "                                                                          98,\n",
       "                                                                          104,\n",
       "                                                                          110,\n",
       "                                                                          116,\n",
       "                                                                          122,\n",
       "                                                                          128,\n",
       "                                                                          134,\n",
       "                                                                          140,\n",
       "                                                                          146,\n",
       "                                                                          152,\n",
       "                                                                          157,\n",
       "                                                                          163,\n",
       "                                                                          169,\n",
       "                                                                          175,\n",
       "                                                                          181, ...],\n",
       "                                        'logistic_regression__solver': ['lbfgs',\n",
       "                                                                        'liblinear',\n",
       "                                                                        'newton-cg',\n",
       "                                                                        'newton-cholesky',\n",
       "                                                                        'sag',\n",
       "                                                                        'saga']},\n",
       "                   random_state=42, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the hyperparameter space\n",
    "max_iter = [int(x) for x in np.linspace(start = 10, stop = 300, num = 50)]\n",
    "solver = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "C = [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]\n",
    "\n",
    "\n",
    "random_grid = {\n",
    "    'logistic_regression__solver': solver,\n",
    "    'logistic_regression__max_iter': max_iter,\n",
    "    'logistic_regression__C': C,\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate the Logistic Regressor\n",
    "full_pipeline_lr = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"logistic_regression\", LogisticRegression(random_state=42)),\n",
    "])\n",
    "\n",
    "lr_random = RandomizedSearchCV(\n",
    "    full_pipeline_lr, param_distributions=random_grid, n_iter=5000, cv=5,\n",
    "    scoring='accuracy', random_state=42, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model to the training data\n",
    "lr_random.fit(titanic, titanic_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cef4cbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logistic_regression__solver': 'lbfgs', 'logistic_regression__max_iter': 15, 'logistic_regression__C': 0.4}\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters found\n",
    "print(lr_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a338e79f",
   "metadata": {},
   "source": [
    "Best logistic regression parameters found after 5000 iterations\n",
    "\n",
    "{'logistic_regression__solver': 'lbfgs', 'logistic_regression__max_iter': 15, 'logistic_regression__C': 0.4}\n",
    "\n",
    "Reaches 81,2% Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "994b06b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8117977528089888"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_random.best_estimator_.score(titanic, titanic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1235f0",
   "metadata": {},
   "source": [
    "### Fine-Tuning SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "03e9da7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 90 is smaller than n_iter=5000. Running 90 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.4, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.4, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.4, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.4, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.4, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.5, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.5, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.5, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.5, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.5, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.5, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.5, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.5, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.6, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.6, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.6, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.6, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.6, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.6, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.6, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.6, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.6, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.6, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.6, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.6, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=9; total time=   0.1s\n",
      "[CV] END .................svc_clf__C=0.9, svc_clf__degree=10; total time=   0.1s\n",
      "[CV] END .................svc_clf__C=0.9, svc_clf__degree=10; total time=   0.1s\n",
      "[CV] END .................svc_clf__C=0.9, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=7; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=8; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=9; total time=   0.1s\n",
      "[CV] END .................svc_clf__C=1.0, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.7, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.7, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.7, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.7, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.7, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.9, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.9, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=1.0, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=1.0, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.1, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.1, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.1, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.6, svc_clf__degree=7; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=0.6, svc_clf__degree=8; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=0.6, svc_clf__degree=8; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=0.6, svc_clf__degree=8; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=6; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=6; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=6; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=7; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=7; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=5; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=6; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=7; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=8; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=9; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.2, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.2, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.2, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.2, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.2, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=6; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..................svc_clf__C=0.7, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.8, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.8, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.8, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.8, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.8, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.8, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=8; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=8; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.9, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=1.0, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=1.0, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=1.0, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.1, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.1, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ................svc_clf__C=0.15, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ................svc_clf__C=0.15, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ................svc_clf__C=0.15, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ................svc_clf__C=0.15, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=2; total time=   0.1s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=1; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=2; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=2; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=2; total time=   0.1s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.3, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.3, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.3, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.1, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.15, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ................svc_clf__C=0.15, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.2, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.25, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ................svc_clf__C=0.25, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ................svc_clf__C=0.25, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ................svc_clf__C=0.25, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ................svc_clf__C=0.25, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ................svc_clf__C=0.25, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=4; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.3, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.35, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.35, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.35, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.35, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.35, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.35, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.35, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.35, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.35, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.35, svc_clf__degree=8; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.35, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.35, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.35, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.35, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.35, svc_clf__degree=9; total time=   0.0s\n",
      "[CV] END ................svc_clf__C=0.35, svc_clf__degree=10; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=5; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.4, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.45, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.45, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.45, svc_clf__degree=1; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.45, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.45, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.45, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.45, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.45, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.45, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.45, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.45, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.45, svc_clf__degree=6; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.45, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.45, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.45, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END .................svc_clf__C=0.45, svc_clf__degree=7; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.5, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.5, svc_clf__degree=2; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.5, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.5, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.5, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.5, svc_clf__degree=3; total time=   0.0s\n",
      "[CV] END ..................svc_clf__C=0.5, svc_clf__degree=3; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                           SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                          (&#x27;onehotencoder&#x27;,\n",
       "                                                                                           OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                transformers=[(&#x27;num&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                                SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                                               (&#x27;standardscaler&#x27;,\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               [&#x27;Fare&#x27;,\n",
       "                                                                                &#x27;Age&#x27;])])),\n",
       "                                             (&#x27;svc_clf&#x27;,\n",
       "                                              SVC(kernel=&#x27;poly&#x27;,\n",
       "                                                  random_state=42))]),\n",
       "                   n_iter=5000, n_jobs=-1,\n",
       "                   param_distributions={&#x27;svc_clf__C&#x27;: [0.1, 0.15, 0.2, 0.25,\n",
       "                                                       0.3, 0.35, 0.4, 0.45,\n",
       "                                                       0.5],\n",
       "                                        &#x27;svc_clf__degree&#x27;: [1, 2, 3, 4, 5, 6, 7,\n",
       "                                                            8, 9, 10]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-190\" type=\"checkbox\" ><label for=\"sk-estimator-id-190\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                           SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                          (&#x27;onehotencoder&#x27;,\n",
       "                                                                                           OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                transformers=[(&#x27;num&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                                SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                                               (&#x27;standardscaler&#x27;,\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               [&#x27;Fare&#x27;,\n",
       "                                                                                &#x27;Age&#x27;])])),\n",
       "                                             (&#x27;svc_clf&#x27;,\n",
       "                                              SVC(kernel=&#x27;poly&#x27;,\n",
       "                                                  random_state=42))]),\n",
       "                   n_iter=5000, n_jobs=-1,\n",
       "                   param_distributions={&#x27;svc_clf__C&#x27;: [0.1, 0.15, 0.2, 0.25,\n",
       "                                                       0.3, 0.35, 0.4, 0.45,\n",
       "                                                       0.5],\n",
       "                                        &#x27;svc_clf__degree&#x27;: [1, 2, 3, 4, 5, 6, 7,\n",
       "                                                            8, 9, 10]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-191\" type=\"checkbox\" ><label for=\"sk-estimator-id-191\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                              SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                             (&#x27;onehotencoder&#x27;,\n",
       "                                                              OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                   transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;standardscaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;Fare&#x27;, &#x27;Age&#x27;])])),\n",
       "                (&#x27;svc_clf&#x27;, SVC(kernel=&#x27;poly&#x27;, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-192\" type=\"checkbox\" ><label for=\"sk-estimator-id-192\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                             SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                            (&#x27;onehotencoder&#x27;,\n",
       "                                             OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                  transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;Fare&#x27;, &#x27;Age&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-193\" type=\"checkbox\" ><label for=\"sk-estimator-id-193\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Fare&#x27;, &#x27;Age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-194\" type=\"checkbox\" ><label for=\"sk-estimator-id-194\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-195\" type=\"checkbox\" ><label for=\"sk-estimator-id-195\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-196\" type=\"checkbox\" ><label for=\"sk-estimator-id-196\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;, &#x27;Embarked&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-197\" type=\"checkbox\" ><label for=\"sk-estimator-id-197\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-198\" type=\"checkbox\" ><label for=\"sk-estimator-id-198\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-199\" type=\"checkbox\" ><label for=\"sk-estimator-id-199\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;poly&#x27;, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('preprocessing',\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[('simpleimputer',\n",
       "                                                                                           SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                          ('onehotencoder',\n",
       "                                                                                           OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                transformers=[('num',\n",
       "                                                                               Pipeline(steps=[('simpleimputer',\n",
       "                                                                                                SimpleImputer(strategy='median')),\n",
       "                                                                                               ('standardscaler',\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               ['Fare',\n",
       "                                                                                'Age'])])),\n",
       "                                             ('svc_clf',\n",
       "                                              SVC(kernel='poly',\n",
       "                                                  random_state=42))]),\n",
       "                   n_iter=5000, n_jobs=-1,\n",
       "                   param_distributions={'svc_clf__C': [0.1, 0.15, 0.2, 0.25,\n",
       "                                                       0.3, 0.35, 0.4, 0.45,\n",
       "                                                       0.5],\n",
       "                                        'svc_clf__degree': [1, 2, 3, 4, 5, 6, 7,\n",
       "                                                            8, 9, 10]},\n",
       "                   random_state=42, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the hyperparameter space\n",
    "#kernel = ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'] #best kernel found is poly. now searching degree\n",
    "C = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "degree= [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "random_grid = {\n",
    "    #'svc_clf__kernel': kernel,\n",
    "    'svc_clf__degree': degree,\n",
    "    'svc_clf__C': C,\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate the SVM Classifier and preprocessing pipeline\n",
    "full_pipeline_svc = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"svc_clf\", svm.SVC(random_state=42, kernel='poly')),\n",
    "])\n",
    "\n",
    "svc_random = RandomizedSearchCV(\n",
    "    full_pipeline_svc, param_distributions=random_grid, n_iter=5000, cv=5,\n",
    "    scoring='accuracy', random_state=42, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model to the training data\n",
    "svc_random.fit(titanic, titanic_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0091843c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc_clf__degree': 4, 'svc_clf__C': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters found\n",
    "print(svc_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0b9e0608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8412921348314607"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_random.best_estimator_.score(titanic, titanic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9263c41",
   "metadata": {},
   "source": [
    "Best SVC hyperparameters found after 5000 iterations:\n",
    "\n",
    "{'svc_clf__degree': 4, 'svc_clf__C': 0.2} with 'poly' kernel\n",
    "\n",
    "Reaches 84,1% Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35300113",
   "metadata": {},
   "source": [
    "### Fine-Tuning KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e0f1f791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 72 is smaller than n_iter=1000. Running 72 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=5, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=5, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=5, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=5, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=5, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=5, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=5, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=7, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=7, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=7, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=7, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=7, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=7, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=7, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=7, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=3, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=3, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=3, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=4, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=4, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=6, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=6, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=6, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=6, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=7, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=7, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=7, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=7, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=7, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=7, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=7, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=7, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=7, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=7, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=7, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=7, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=7, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=7, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=7, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=7, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.1s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=5, kneigh_clf__weights=None; total time=   0.1s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=5, kneigh_clf__weights=None; total time=   0.1s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=5, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=6, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=6, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=6, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=6, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=6, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=8, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=8, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=8, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=3, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=3, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=3, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=5, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=5, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=5, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=5, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=5, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=5, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=5, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=5, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=6, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=6, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=6, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=6, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=7, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=7, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=7, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=7, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=6, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=7, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=7, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=7, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=7, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=7, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=3, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=6, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=6, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=7, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=7, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=7, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=7, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=7, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=7, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=3, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=3, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=4, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=5, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=6, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=6, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=6, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=8, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=8, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=8, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=8, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=8, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=6, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=6, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=6, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=6, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=6, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=6, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=6, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=6, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=4, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=6, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=6, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=6, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=6, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=6, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=6, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=6, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=6, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=7, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=8, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=8, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=8, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=8, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=8, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=8, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=brute, kneigh_clf__n_neighbors=8, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=3, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=3, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=4, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=4, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=4, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=5, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=6, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=6, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=6, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=6, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=7, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=7, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=7, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=8, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=8, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=8, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=8, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=auto, kneigh_clf__n_neighbors=8, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=6, kneigh_clf__weights=distance; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=6, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=6, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=6, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=6, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=6, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=7, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=7, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=ball_tree, kneigh_clf__n_neighbors=8, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=3, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=4, kneigh_clf__weights=None; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=uniform; total time=   0.0s\n",
      "[CV] END kneigh_clf__algorithm=kd_tree, kneigh_clf__n_neighbors=5, kneigh_clf__weights=distance; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n",
      "/home/igolas0/Programs/anaconda3/envs/homl3/lib/python3.10/site-packages/sklearn/neighbors/_base.py:513: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                           SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                          (&#x27;onehotencoder&#x27;,\n",
       "                                                                                           OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                transformers=[(&#x27;num&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                                SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                                               (&#x27;standardscaler&#x27;,\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               [&#x27;Fare&#x27;,\n",
       "                                                                                &#x27;Age&#x27;])])),\n",
       "                                             (&#x27;kneigh_clf&#x27;,\n",
       "                                              KNeighborsClassifier())]),\n",
       "                   n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={&#x27;kneigh_clf__algorithm&#x27;: [&#x27;auto&#x27;,\n",
       "                                                                  &#x27;ball_tree&#x27;,\n",
       "                                                                  &#x27;kd_tree&#x27;,\n",
       "                                                                  &#x27;brute&#x27;],\n",
       "                                        &#x27;kneigh_clf__n_neighbors&#x27;: [3, 4, 5, 6,\n",
       "                                                                    7, 8],\n",
       "                                        &#x27;kneigh_clf__weights&#x27;: [&#x27;uniform&#x27;,\n",
       "                                                                &#x27;distance&#x27;,\n",
       "                                                                None]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-210\" type=\"checkbox\" ><label for=\"sk-estimator-id-210\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                           SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                          (&#x27;onehotencoder&#x27;,\n",
       "                                                                                           OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                transformers=[(&#x27;num&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                                SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                                               (&#x27;standardscaler&#x27;,\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               [&#x27;Fare&#x27;,\n",
       "                                                                                &#x27;Age&#x27;])])),\n",
       "                                             (&#x27;kneigh_clf&#x27;,\n",
       "                                              KNeighborsClassifier())]),\n",
       "                   n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={&#x27;kneigh_clf__algorithm&#x27;: [&#x27;auto&#x27;,\n",
       "                                                                  &#x27;ball_tree&#x27;,\n",
       "                                                                  &#x27;kd_tree&#x27;,\n",
       "                                                                  &#x27;brute&#x27;],\n",
       "                                        &#x27;kneigh_clf__n_neighbors&#x27;: [3, 4, 5, 6,\n",
       "                                                                    7, 8],\n",
       "                                        &#x27;kneigh_clf__weights&#x27;: [&#x27;uniform&#x27;,\n",
       "                                                                &#x27;distance&#x27;,\n",
       "                                                                None]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-211\" type=\"checkbox\" ><label for=\"sk-estimator-id-211\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                              SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                             (&#x27;onehotencoder&#x27;,\n",
       "                                                              OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                   transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;standardscaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;Fare&#x27;, &#x27;Age&#x27;])])),\n",
       "                (&#x27;kneigh_clf&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-212\" type=\"checkbox\" ><label for=\"sk-estimator-id-212\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                             SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                            (&#x27;onehotencoder&#x27;,\n",
       "                                             OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                  transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;Fare&#x27;, &#x27;Age&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-213\" type=\"checkbox\" ><label for=\"sk-estimator-id-213\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Fare&#x27;, &#x27;Age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-214\" type=\"checkbox\" ><label for=\"sk-estimator-id-214\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-215\" type=\"checkbox\" ><label for=\"sk-estimator-id-215\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-216\" type=\"checkbox\" ><label for=\"sk-estimator-id-216\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;, &#x27;Embarked&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-217\" type=\"checkbox\" ><label for=\"sk-estimator-id-217\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-218\" type=\"checkbox\" ><label for=\"sk-estimator-id-218\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-219\" type=\"checkbox\" ><label for=\"sk-estimator-id-219\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('preprocessing',\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[('simpleimputer',\n",
       "                                                                                           SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                          ('onehotencoder',\n",
       "                                                                                           OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                transformers=[('num',\n",
       "                                                                               Pipeline(steps=[('simpleimputer',\n",
       "                                                                                                SimpleImputer(strategy='median')),\n",
       "                                                                                               ('standardscaler',\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               ['Fare',\n",
       "                                                                                'Age'])])),\n",
       "                                             ('kneigh_clf',\n",
       "                                              KNeighborsClassifier())]),\n",
       "                   n_iter=1000, n_jobs=-1,\n",
       "                   param_distributions={'kneigh_clf__algorithm': ['auto',\n",
       "                                                                  'ball_tree',\n",
       "                                                                  'kd_tree',\n",
       "                                                                  'brute'],\n",
       "                                        'kneigh_clf__n_neighbors': [3, 4, 5, 6,\n",
       "                                                                    7, 8],\n",
       "                                        'kneigh_clf__weights': ['uniform',\n",
       "                                                                'distance',\n",
       "                                                                None]},\n",
       "                   random_state=42, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the hyperparameter space\n",
    "algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute'] \n",
    "weights = ['uniform', 'distance']\n",
    "weights.append(None)\n",
    "n_neighbors = [3, 4, 5, 6, 7, 8]\n",
    "\n",
    "random_grid = {\n",
    "    'kneigh_clf__algorithm': algorithm,\n",
    "    'kneigh_clf__n_neighbors': n_neighbors,\n",
    "    'kneigh_clf__weights': weights,\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate the KNeighbors Classifier and preprocessing pipeline\n",
    "full_pipeline_kneigh = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"kneigh_clf\", KNeighborsClassifier()),\n",
    "])\n",
    "\n",
    "kneigh_random = RandomizedSearchCV(\n",
    "    full_pipeline_kneigh, param_distributions=random_grid, n_iter=1000, cv=5,\n",
    "    scoring='accuracy', random_state=42, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model to the training data\n",
    "kneigh_random.fit(titanic, titanic_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "892904e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kneigh_clf__weights': 'uniform', 'kneigh_clf__n_neighbors': 5, 'kneigh_clf__algorithm': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "print(kneigh_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "be00ba42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8651685393258427"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kneigh_random.best_estimator_.score(titanic, titanic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a908ab74",
   "metadata": {},
   "source": [
    "Best KNeighbors Classifier hyperparameters found after 1000 iterations:\n",
    "\n",
    "{'kneigh_clf__weights': 'uniform', 'kneigh_clf__n_neighbors': 5, 'kneigh_clf__algorithm': 'auto'}\n",
    "\n",
    "Reaches 86,5% Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506db85",
   "metadata": {},
   "source": [
    "# Ensemble methods "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91a1b0e",
   "metadata": {},
   "source": [
    "### VotingClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3264b96",
   "metadata": {},
   "source": [
    "We will combine the best models found using a VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8597103d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the ensemble model: 0.865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Instantiate multiple classifiers with previously optimized hyperparameters and preprocessing pipeline\n",
    "pipe_rf = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"random_forest\", RandomForestClassifier(random_state=42, n_estimators = 2500, \n",
    "                                        min_samples_split = 20, bootstrap = False,\n",
    "                                        min_samples_leaf = 3, max_features = 'sqrt', max_depth = None)),\n",
    "])\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"logistic_regression\", LogisticRegression(random_state=42, solver = 'lbfgs', max_iter = 15, C = 0.4)),\n",
    "])\n",
    "\n",
    "pipe_svc = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"svc_clf\", svm.SVC(random_state=42, kernel='poly', degree = 4, C = 0.2, probability=True)),\n",
    "])\n",
    "pipe_kneigh = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"kneigh_clf\", KNeighborsClassifier(weights = 'uniform', n_neighbors = 5, algorithm = 'auto')),\n",
    "])\n",
    "\n",
    "# Define a voting classifier that combines the predictions of the four models\n",
    "voting = VotingClassifier(\n",
    "    estimators=[\n",
    "                ('rf', pipe_rf),\n",
    "                #('lr', pipe_lr),\n",
    "                ('svc', pipe_svc),\n",
    "                ('kneigh', pipe_kneigh)\n",
    "    ], \n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# Fit the voting classifier to the training data\n",
    "voting.fit(titanic, titanic_labels)\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "accuracy = voting.score(titanic, titanic_labels)\n",
    "print(\"Accuracy score of the ensemble model: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450b52a9",
   "metadata": {},
   "source": [
    "### Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9dbe375f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the ensemble model: 0.851\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "                ('rf', pipe_rf),\n",
    "                #('lr', pipe_lr),\n",
    "                ('svc', pipe_svc),\n",
    "                ('kneigh', pipe_kneigh)\n",
    "    ], \n",
    "    final_estimator=RandomForestClassifier(random_state=43,  n_estimators = 2500, \n",
    "                                        min_samples_split = 20, bootstrap = False,\n",
    "                                        min_samples_leaf = 3, max_features = 'sqrt', max_depth = None),\n",
    "    cv=5 #number of cross-validation folds\n",
    ")\n",
    "stacking_clf.fit(titanic, titanic_labels)\n",
    "\n",
    "accuracy = stacking_clf.score(titanic, titanic_labels)\n",
    "print(\"Accuracy score of the ensemble model: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42478c",
   "metadata": {},
   "source": [
    "### Adaboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9a810de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1204; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1387; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1306; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1551; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1551; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1632; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1693; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1204; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1204; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1387; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1571; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=2000; total time=   3.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=2000; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1367; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1367; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1183; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1775; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1387; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1693; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1693; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1612; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1244; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1693; total time=   4.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1734; total time=   4.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1040; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1040; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1755; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1714; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1714; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1938; total time=   4.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1367; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1795; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1795; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1714; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1714; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1122; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1755; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1918; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1265; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1265; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1653; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1142; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1142; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1857; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1061; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1653; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1306; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1306; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1836; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1510; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1510; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1285; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1591; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1122; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1408; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1408; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1489; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1653; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1653; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1469; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1081; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1265; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1816; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1816; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1918; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1979; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1020; total time=   1.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1102; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1836; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1122; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1122; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1183; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1306; total time=   2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1204; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1387; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1387; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1306; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1551; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1632; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1693; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1204; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1204; total time=   1.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1387; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1571; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1571; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=2000; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1102; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1102; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1367; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1183; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1775; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1775; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1693; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1612; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1612; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1244; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1693; total time=   4.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1734; total time=   4.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1040; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1040; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1755; total time=   4.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1714; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1938; total time=   3.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1367; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1367; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1795; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1448; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1448; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1714; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1122; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1755; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1918; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1918; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1653; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1653; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1857; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1061; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1061; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1653; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1306; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1836; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1510; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1510; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1285; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1591; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1122; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1122; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1408; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1489; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1653; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1469; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1469; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1081; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1265; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1816; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1918; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1979; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1020; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1020; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1102; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1102; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1836; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1122; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1183; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1306; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1306; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1204; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1204; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1387; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1306; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1551; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1632; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1632; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1693; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1204; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1387; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1571; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=2000; total time=   3.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1102; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1102; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1367; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1183; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1775; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1387; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1387; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1693; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1612; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1244; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1244; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1693; total time=   3.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1734; total time=   4.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1734; total time=   4.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1755; total time=   4.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1755; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1714; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1938; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1367; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1795; total time=   3.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1448; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1714; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1122; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1122; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1755; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1918; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1265; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1265; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1653; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1142; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1857; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1857; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1061; total time=   1.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1653; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1306; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1836; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1836; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1285; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1285; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1591; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1122; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1408; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1489; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1489; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1653; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1469; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1081; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1265; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1265; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1816; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1918; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1979; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1979; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1020; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1102; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1836; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1122; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1122; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1183; total time=   1.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1306; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1755; total time=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1204; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1387; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1306; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1306; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1551; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1632; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1693; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1693; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1387; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1387; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1571; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=2000; total time=   3.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1102; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1367; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1183; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1183; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1775; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1387; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1387; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1693; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1612; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1244; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1693; total time=   4.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1693; total time=   5.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1734; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1040; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1755; total time=   3.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1714; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1938; total time=   3.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1938; total time=   3.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1367; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1795; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1448; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1448; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1714; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1122; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1755; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1755; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1918; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1265; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1653; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1142; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1142; total time=   1.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1857; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1061; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1653; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1653; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1306; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1836; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1510; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1285; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1591; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1591; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1122; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1408; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1489; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1653; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1469; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1081; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1081; total time=   1.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1265; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1816; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1918; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1918; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1979; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1020; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1102; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1836; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1836; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1183; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1183; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1306; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1755; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1755; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1918; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1918; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1530; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1530; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1591; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1734; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1734; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1979; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1408; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1224; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1224; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1795; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1632; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1326; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1326; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1081; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1122; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1469; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1489; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1591; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1755; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1755; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1244; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1775; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1183; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1653; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1653; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1734; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1530; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1979; total time=   3.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1224; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1224; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1469; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1795; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1102; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1102; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1367; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1408; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1204; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1204; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1714; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1938; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1204; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1204; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1000; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1183; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1612; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1571; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1571; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1244; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1244; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1673; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1816; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1163; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1163; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1775; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1714; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1591; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1693; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1693; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1816; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1632; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1367; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1367; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1285; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=2000; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1285; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1285; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1510; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1693; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1428; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1428; total time=   2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1755; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1918; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1530; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1530; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1530; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1591; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1734; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1979; total time=   3.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1408; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1408; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1224; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1795; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1632; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1326; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1081; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1081; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1122; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1469; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1489; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1489; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1591; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1755; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1244; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1775; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1775; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1183; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1653; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1734; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1530; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1979; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1979; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1224; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1469; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1795; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1102; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1367; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1367; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1408; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1204; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1714; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1714; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1938; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1204; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1000; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1000; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1183; total time=   1.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1612; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1571; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1224; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1224; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1244; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1673; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1816; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1163; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1163; total time=   1.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1775; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1714; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1591; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1591; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1693; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1816; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1632; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1632; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1367; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1285; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=2000; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1285; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1285; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1510; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1693; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1428; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=2000; total time=   3.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1816; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1918; total time=   3.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1530; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1530; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1530; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1591; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1734; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1979; total time=   3.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1979; total time=   3.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1224; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1795; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1632; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1632; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1326; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1081; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1122; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1469; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1469; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1489; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1591; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1755; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1244; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1244; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1775; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1183; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1183; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1653; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1734; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1530; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1530; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1979; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1224; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1469; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1469; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1795; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1102; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1367; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1408; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1408; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1204; total time=   1.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1714; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1938; total time=   3.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1204; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1204; total time=   1.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1000; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1183; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1612; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1612; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1571; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1224; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1244; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1673; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1673; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1816; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1163; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1775; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1714; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1714; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1591; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1693; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1816; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1816; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1632; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1367; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1285; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=2000; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=2000; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1510; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1510; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1693; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1428; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=2000; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=2000; total time=   3.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1816; total time=   2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1755; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1918; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1530; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1530; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1591; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1591; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1734; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1979; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1408; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1408; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1224; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1795; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1795; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1632; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1326; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1081; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1122; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1122; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1469; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1489; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1591; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1591; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1755; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1244; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1775; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1183; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1653; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1734; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1734; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1530; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1979; total time=   3.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1224; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1469; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1795; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1795; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1102; total time=   1.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1367; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1408; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1204; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1714; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1938; total time=   3.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1938; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1000; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1183; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1183; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1612; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1571; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1224; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1224; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1244; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1673; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1816; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1816; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1775; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1775; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1714; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1591; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1693; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1816; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1632; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1367; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1285; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1285; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=2000; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1285; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1510; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1693; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1693; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1428; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=2000; total time=   3.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1816; total time=   3.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1979; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1979; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=2000; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1816; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1979; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1897; total time=   3.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1897; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1795; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1918; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1183; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1183; total time=   1.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1510; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1469; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1775; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1775; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1632; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1448; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1979; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1979; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1734; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1938; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1693; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1857; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1551; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1551; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1061; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1040; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1938; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1938; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1510; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1857; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1938; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1367; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1306; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1306; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1081; total time=   1.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1163; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1775; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1959; total time=   3.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1346; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1346; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1653; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1102; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1102; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1673; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1000; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1877; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1632; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1061; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1061; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1653; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1693; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1897; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1897; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1448; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1816; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1326; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1326; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1795; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1306; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1224; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1367; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1367; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1142; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1408; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1897; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1795; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1489; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1489; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1836; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1204; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1000; total time=   1.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1000; total time=   1.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1755; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1571; total time=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1816; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1979; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1897; total time=   3.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1795; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1918; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1918; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1510; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1510; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1469; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1775; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1632; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1448; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1448; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1979; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1734; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1938; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1693; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1693; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1857; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1551; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1061; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1061; total time=   1.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1040; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1938; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1510; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1510; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1857; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1938; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1367; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1367; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1306; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1081; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1163; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1775; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1775; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1959; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1346; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1653; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1102; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1673; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1000; total time=   1.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1000; total time=   1.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1877; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1877; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1632; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1061; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1653; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1693; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1693; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1897; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1448; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1816; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1816; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1795; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1306; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1306; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1224; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1367; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1142; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1142; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1408; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1897; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1897; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1795; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1489; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1836; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1204; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1204; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1000; total time=   1.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1755; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1571; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1571; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1000; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1897; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1795; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1918; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1183; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1183; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1510; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1469; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1469; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1775; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1632; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1448; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1979; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1734; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1734; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1938; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1693; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1857; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1857; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1551; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1040; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1040; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1938; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1510; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1857; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1938; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1938; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1367; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1306; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1081; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1081; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1163; total time=   1.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1775; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1959; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1959; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1346; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1653; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1102; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1673; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1673; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1000; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1877; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1632; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1061; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1061; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1653; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1693; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1897; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1448; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1448; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1816; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1326; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1326; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1795; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1306; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1224; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1224; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1367; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1142; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1408; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1408; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1897; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1795; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1489; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1836; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1836; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1000; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1755; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1755; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1000; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1000; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1346; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1081; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1877; total time=   3.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1979; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1897; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1795; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1795; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1918; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1183; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1510; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1469; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1775; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1632; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1632; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1448; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1979; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1734; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1938; total time=   3.6s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1938; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1693; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1857; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1551; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1061; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1061; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1040; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1938; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1510; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1857; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1857; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1938; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1367; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1306; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1081; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1163; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1163; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1775; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1959; total time=   3.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1346; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1653; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1653; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1102; total time=   2.0s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1673; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1000; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1877; total time=   3.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1632; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1632; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1653; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1653; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1693; total time=   2.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1897; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1448; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1816; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1326; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1795; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1795; total time=   3.0s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1306; total time=   2.4s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1224; total time=   1.6s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1367; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1142; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.1, ada_clf__n_estimators=1408; total time=   3.1s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1897; total time=   3.2s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1795; total time=   2.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1795; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1489; total time=   2.5s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1836; total time=   2.7s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1204; total time=   2.1s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1204; total time=   2.3s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1000; total time=   1.7s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.35, ada_clf__n_estimators=1755; total time=   2.2s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.3, ada_clf__n_estimators=1571; total time=   2.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1000; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.2, ada_clf__n_estimators=1000; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1346; total time=   1.9s\n",
      "[CV] END ada_clf__algorithm=SAMME, ada_clf__learning_rate=1.15, ada_clf__n_estimators=1081; total time=   1.8s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1877; total time=   3.3s\n",
      "[CV] END ada_clf__algorithm=SAMME.R, ada_clf__learning_rate=1.25, ada_clf__n_estimators=1877; total time=   3.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                           SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                          (&#x27;onehotencoder&#x27;,\n",
       "                                                                                           OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                transformers=[(&#x27;num&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                                SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                                               (&#x27;standardscaler&#x27;,\n",
       "                                                                                                StandardScaler()...\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={&#x27;ada_clf__algorithm&#x27;: [&#x27;SAMME&#x27;,\n",
       "                                                               &#x27;SAMME.R&#x27;],\n",
       "                                        &#x27;ada_clf__learning_rate&#x27;: [1.1, 1.15,\n",
       "                                                                   1.2, 1.25,\n",
       "                                                                   1.3, 1.35],\n",
       "                                        &#x27;ada_clf__n_estimators&#x27;: [1000, 1020,\n",
       "                                                                  1040, 1061,\n",
       "                                                                  1081, 1102,\n",
       "                                                                  1122, 1142,\n",
       "                                                                  1163, 1183,\n",
       "                                                                  1204, 1224,\n",
       "                                                                  1244, 1265,\n",
       "                                                                  1285, 1306,\n",
       "                                                                  1326, 1346,\n",
       "                                                                  1367, 1387,\n",
       "                                                                  1408, 1428,\n",
       "                                                                  1448, 1469,\n",
       "                                                                  1489, 1510,\n",
       "                                                                  1530, 1551,\n",
       "                                                                  1571, 1591, ...]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                           SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                          (&#x27;onehotencoder&#x27;,\n",
       "                                                                                           OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                transformers=[(&#x27;num&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                                SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                                               (&#x27;standardscaler&#x27;,\n",
       "                                                                                                StandardScaler()...\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={&#x27;ada_clf__algorithm&#x27;: [&#x27;SAMME&#x27;,\n",
       "                                                               &#x27;SAMME.R&#x27;],\n",
       "                                        &#x27;ada_clf__learning_rate&#x27;: [1.1, 1.15,\n",
       "                                                                   1.2, 1.25,\n",
       "                                                                   1.3, 1.35],\n",
       "                                        &#x27;ada_clf__n_estimators&#x27;: [1000, 1020,\n",
       "                                                                  1040, 1061,\n",
       "                                                                  1081, 1102,\n",
       "                                                                  1122, 1142,\n",
       "                                                                  1163, 1183,\n",
       "                                                                  1204, 1224,\n",
       "                                                                  1244, 1265,\n",
       "                                                                  1285, 1306,\n",
       "                                                                  1326, 1346,\n",
       "                                                                  1367, 1387,\n",
       "                                                                  1408, 1428,\n",
       "                                                                  1448, 1469,\n",
       "                                                                  1489, 1510,\n",
       "                                                                  1530, 1551,\n",
       "                                                                  1571, 1591, ...]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                              SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                             (&#x27;onehotencoder&#x27;,\n",
       "                                                              OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                   transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;standardscaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;Fare&#x27;, &#x27;Age&#x27;])])),\n",
       "                (&#x27;ada_clf&#x27;,\n",
       "                 AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                                    random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                             SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                            (&#x27;onehotencoder&#x27;,\n",
       "                                             OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                  transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;Fare&#x27;, &#x27;Age&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" ><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Fare&#x27;, &#x27;Age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-84\" type=\"checkbox\" ><label for=\"sk-estimator-id-84\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-85\" type=\"checkbox\" ><label for=\"sk-estimator-id-85\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-86\" type=\"checkbox\" ><label for=\"sk-estimator-id-86\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;, &#x27;Embarked&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-87\" type=\"checkbox\" ><label for=\"sk-estimator-id-87\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-88\" type=\"checkbox\" ><label for=\"sk-estimator-id-88\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-89\" type=\"checkbox\" ><label for=\"sk-estimator-id-89\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ada_clf: AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-90\" type=\"checkbox\" ><label for=\"sk-estimator-id-90\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-91\" type=\"checkbox\" ><label for=\"sk-estimator-id-91\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=1)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('preprocessing',\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[('simpleimputer',\n",
       "                                                                                           SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                          ('onehotencoder',\n",
       "                                                                                           OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                transformers=[('num',\n",
       "                                                                               Pipeline(steps=[('simpleimputer',\n",
       "                                                                                                SimpleImputer(strategy='median')),\n",
       "                                                                                               ('standardscaler',\n",
       "                                                                                                StandardScaler()...\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={'ada_clf__algorithm': ['SAMME',\n",
       "                                                               'SAMME.R'],\n",
       "                                        'ada_clf__learning_rate': [1.1, 1.15,\n",
       "                                                                   1.2, 1.25,\n",
       "                                                                   1.3, 1.35],\n",
       "                                        'ada_clf__n_estimators': [1000, 1020,\n",
       "                                                                  1040, 1061,\n",
       "                                                                  1081, 1102,\n",
       "                                                                  1122, 1142,\n",
       "                                                                  1163, 1183,\n",
       "                                                                  1204, 1224,\n",
       "                                                                  1244, 1265,\n",
       "                                                                  1285, 1306,\n",
       "                                                                  1326, 1346,\n",
       "                                                                  1367, 1387,\n",
       "                                                                  1408, 1428,\n",
       "                                                                  1448, 1469,\n",
       "                                                                  1489, 1510,\n",
       "                                                                  1530, 1551,\n",
       "                                                                  1571, 1591, ...]},\n",
       "                   random_state=42, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the hyperparameter space\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1000, stop = 2000, num = 50)]\n",
    "algorithm = ['SAMME', 'SAMME.R']\n",
    "learning_rate = [1.1, 1.15, 1.2, 1.25, 1.3, 1.35]\n",
    "\n",
    "\n",
    "random_grid = {\n",
    "    'ada_clf__n_estimators': n_estimators,\n",
    "    'ada_clf__algorithm': algorithm,\n",
    "    'ada_clf__learning_rate': learning_rate,\n",
    "}\n",
    "\n",
    "pipe_ada = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"ada_clf\", AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), random_state=42)),\n",
    "])\n",
    "\n",
    "ada_random = RandomizedSearchCV(\n",
    "    pipe_ada, param_distributions=random_grid, n_iter=200, cv=5,\n",
    "    scoring='accuracy', random_state=42, n_jobs=-1, verbose=2)\n",
    "\n",
    "\n",
    "ada_random.fit(titanic, titanic_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2d40a9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ada_clf__n_estimators': 1224, 'ada_clf__learning_rate': 1.1, 'ada_clf__algorithm': 'SAMME'}\n"
     ]
    }
   ],
   "source": [
    "print(ada_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c8987f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8300561797752809"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_random.best_estimator_.score(titanic, titanic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f001460",
   "metadata": {},
   "source": [
    "Best Adaboost hyperparameters found after 100 iterations:\n",
    "\n",
    "{'ada_clf__n_estimators': 1024, 'ada_clf__learning_rate': 1.25, 'ada_clf__algorithm': 'SAMME'}\n",
    "\n",
    "Reaches 83,7% Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909190c",
   "metadata": {},
   "source": [
    "### GBRT (Gradient Boosting Regression Trees) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "007d2264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2326; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2693; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3306; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3306; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3795; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3183; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2734; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3469; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3469; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3510; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3959; total time=   4.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3102; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2979; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2979; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2938; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3632; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2857; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2857; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2816; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2775; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2775; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3428; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3020; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2448; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2448; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2204; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2204; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2326; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2326; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3142; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3510; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3510; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2122; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2938; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3918; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3918; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3020; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3020; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3265; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2163; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2326; total time=   1.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2693; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3306; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3795; total time=   4.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3183; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3183; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2734; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3469; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3510; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3959; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3959; total time=   4.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3102; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2979; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2938; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2938; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3632; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2857; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2816; total time=   1.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2775; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3428; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3020; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3020; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2448; total time=   1.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2204; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2204; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2204; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2326; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3142; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3510; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3510; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2122; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2938; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3918; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2204; total time=   1.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2204; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3020; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3265; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2163; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2163; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3877; total time=   4.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2326; total time=   0.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2326; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2693; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3306; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3795; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3795; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3183; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2734; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3469; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3510; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3510; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3959; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3102; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2979; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2979; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2938; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3632; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2857; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2857; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2816; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2775; total time=   1.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3428; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3428; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2448; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2204; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2204; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2326; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3142; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3142; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2122; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2938; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2938; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3918; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2204; total time=   1.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3020; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3265; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3265; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2163; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3877; total time=   4.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3428; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2326; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2693; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2693; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3306; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3795; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3183; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2734; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2734; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3469; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3510; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3959; total time=   4.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3102; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3102; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2938; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3632; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3632; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2816; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2816; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2775; total time=   1.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3428; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3020; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3020; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2448; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2204; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2204; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2204; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2326; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3142; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3510; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2122; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2122; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2938; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3918; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2204; total time=   1.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2204; total time=   1.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3020; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3265; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2163; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3877; total time=   5.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3877; total time=   5.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3877; total time=   4.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3428; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3428; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3469; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2122; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2122; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2040; total time=   1.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2653; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3795; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3714; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3714; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3632; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2244; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2530; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=4000; total time=   4.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3714; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3714; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3959; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3755; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2979; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2979; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2326; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2204; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2367; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2408; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2408; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3224; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3102; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2816; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2816; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2285; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2122; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3836; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3714; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3714; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2612; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=4000; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=4000; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3387; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3918; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3428; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3428; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3469; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2122; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2040; total time=   1.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2040; total time=   1.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2653; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3795; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3714; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3632; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3632; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2244; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2530; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2530; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=4000; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3714; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3959; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3755; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3755; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2979; total time=   1.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2326; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2204; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2204; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2367; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2408; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3224; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3102; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3102; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2285; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2122; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2122; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3836; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3714; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2612; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2612; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=4000; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3387; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3918; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3918; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2653; total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3469; total time=   4.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3469; total time=   4.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2040; total time=   1.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2653; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2653; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3795; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3714; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3632; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2244; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2244; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2530; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=4000; total time=   4.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3714; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3714; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3959; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3755; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2979; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2326; total time=   1.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2326; total time=   1.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2204; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2367; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2367; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2408; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3224; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3102; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2816; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2816; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2285; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2122; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3836; total time=   4.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3836; total time=   4.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3714; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=4000; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3387; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3387; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3918; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3510; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2653; total time=   1.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2653; total time=   1.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3673; total time=   4.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3469; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2122; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2122; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2040; total time=   0.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2653; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3795; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3795; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3714; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3632; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2244; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2530; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=4000; total time=   4.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=4000; total time=   4.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3959; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3959; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3755; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2979; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2326; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2204; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2367; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2408; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3224; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3224; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3102; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2816; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2285; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2285; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2122; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3836; total time=   4.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3714; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2612; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2612; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=4000; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3387; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3918; total time=   4.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3510; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3510; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3510; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3673; total time=   4.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3918; total time=   4.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3510; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2653; total time=   1.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2653; total time=   1.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3673; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3918; total time=   4.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2000; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2000; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3959; total time=   5.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2734; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2734; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2285; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3428; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3755; total time=   4.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3795; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3795; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2571; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2081; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3387; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2979; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2979; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2734; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2040; total time=   1.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2693; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3020; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3020; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3224; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2163; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3469; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3469; total time=   4.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2489; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2653; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2408; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2408; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3346; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2163; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2204; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3551; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2489; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3714; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3714; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2000; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2000; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3959; total time=   5.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2734; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2734; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2285; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3428; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3428; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3755; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3795; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2571; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2081; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2081; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3387; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2979; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2979; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2040; total time=   1.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2040; total time=   0.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2693; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3020; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3020; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3224; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2163; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2163; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3469; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2326; total time=   1.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2489; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2489; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2653; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2408; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3346; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3346; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2204; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2204; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3551; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3551; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2489; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3714; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3428; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2775; total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3673; total time=   4.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3673; total time=   4.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3918; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2000; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3959; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2734; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2285; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2285; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3428; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3755; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3755; total time=   4.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2571; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2571; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2081; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3387; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3387; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2734; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2734; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2040; total time=   1.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2693; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2693; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3224; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2163; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2163; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3469; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2326; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2326; total time=   1.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2489; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2653; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2653; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3346; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2163; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2163; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2204; total time=   1.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3551; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2489; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2489; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3714; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3428; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2775; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3918; total time=   4.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3918; total time=   4.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3959; total time=   5.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3959; total time=   5.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2285; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3428; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3755; total time=   4.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3795; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3795; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2571; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2081; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3387; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2979; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2734; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2734; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2040; total time=   1.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2693; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3020; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3224; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3224; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3469; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2326; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2326; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2489; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2653; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2408; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2408; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3346; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2163; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2163; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2204; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3551; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2489; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3714; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3428; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3428; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2775; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2244; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2244; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3428; total time=   4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3428; total time=   1.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2775; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2244; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2244; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3428; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3142; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2897; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2897; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2938; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3387; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2612; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3551; total time=   4.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3551; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2653; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2081; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3306; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2244; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2244; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3306; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3591; total time=   4.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3306; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3306; total time=   1.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3061; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3061; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3061; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3142; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2775; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2612; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3877; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3877; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2367; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3510; total time=   4.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=None, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3591; total time=   5.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2530; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2530; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3142; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2938; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2938; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2000; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3061; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2775; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3428; total time=   4.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3142; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3142; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2897; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2938; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3387; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3387; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2612; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3551; total time=   4.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2653; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2081; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2081; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3306; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2244; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2244; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3306; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3591; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3306; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3306; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3061; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3061; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3142; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3142; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2367; total time=   1.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2775; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2612; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3877; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3877; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2367; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3510; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3510; total time=   4.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=None, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3591; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2530; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3142; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2938; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2938; total time=   1.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2000; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3061; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3836; total time=   5.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2244; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3428; total time=   4.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3428; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3142; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2897; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2938; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3387; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2612; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2612; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3551; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2653; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2081; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3306; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3306; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3306; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3591; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3591; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3306; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3061; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3061; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3142; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2367; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2367; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2775; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2612; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2612; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2367; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2367; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3510; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=None, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3591; total time=   4.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2530; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2530; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3142; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2938; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2000; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2000; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3061; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3836; total time=   4.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3428; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3020; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3142; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2897; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2938; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2938; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3387; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2612; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3551; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2653; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2653; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2081; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3306; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2244; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3306; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3306; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3591; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3061; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3061; total time=   1.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3061; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3142; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2367; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2367; total time=   1.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2775; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2775; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2612; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3877; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2367; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3510; total time=   4.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=None, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3591; total time=   4.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=None, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3591; total time=   4.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3142; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3142; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2000; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3061; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3061; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3836; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3428; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3428; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3020; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3795; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2244; total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3836; total time=   4.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3428; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3428; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3020; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3795; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2244; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3755; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3755; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2367; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3591; total time=   4.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3918; total time=   5.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2204; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2204; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2653; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3183; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2489; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2693; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2693; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3061; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3061; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3061; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3959; total time=   4.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3510; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3510; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3959; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2653; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3877; total time=   4.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2367; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2367; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2081; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2040; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2040; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3959; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3836; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2367; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3224; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3224; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3510; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3632; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2040; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3836; total time=   5.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3020; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3795; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3795; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2244; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3755; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2367; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3591; total time=   4.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3591; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3918; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2204; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2653; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3183; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2489; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2489; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2693; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3061; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3061; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3061; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3959; total time=   5.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3510; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3959; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3959; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2653; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3877; total time=   4.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2367; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2367; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2081; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2040; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3959; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3836; total time=   4.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3836; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3224; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2285; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2285; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3510; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3510; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3632; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2040; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2204; total time=   2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3020; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3795; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2244; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3755; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2367; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2367; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3591; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3918; total time=   4.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3918; total time=   4.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2653; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3183; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3183; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2489; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2693; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3061; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3061; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3959; total time=   4.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3959; total time=   5.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3959; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2653; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2653; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3877; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2367; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2081; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2081; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2040; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3959; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3836; total time=   4.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2367; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2367; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3224; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2285; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2285; total time=   1.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3510; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3632; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3632; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2204; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2204; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2122; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3346; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2244; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3755; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2367; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3591; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3918; total time=   4.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2204; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2204; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2653; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2653; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3183; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2489; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2693; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3061; total time=   4.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3061; total time=   4.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3959; total time=   5.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3510; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3510; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3959; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2653; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3877; total time=   5.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3877; total time=   5.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2081; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2040; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3959; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3959; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3836; total time=   4.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2367; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2367; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=8, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3224; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2285; total time=   1.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3510; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3632; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2040; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2040; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2204; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2122; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3346; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2734; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2734; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2897; total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2040; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2204; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2122; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3346; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3346; total time=   4.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2897; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2571; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2571; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3469; total time=   3.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2367; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3265; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3265; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3061; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3387; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3714; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3224; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3224; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2285; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2285; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2693; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2244; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2040; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2040; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2244; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2408; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3714; total time=   4.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2326; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2326; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3265; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3836; total time=   5.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3959; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3959; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3142; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2938; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2857; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2857; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3387; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2081; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2530; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2326; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2122; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=5, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2122; total time=   1.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3346; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2734; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2734; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2897; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2571; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3469; total time=   4.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3469; total time=   4.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3265; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3061; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3061; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3387; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3714; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3224; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2367; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2367; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2285; total time=   1.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2693; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2244; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2040; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2244; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2244; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2408; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3714; total time=   4.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2326; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2326; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3265; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3836; total time=   5.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3959; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3142; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3142; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2938; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2857; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3387; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2081; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2081; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2530; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2326; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2244; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2734; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2897; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2897; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2571; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3469; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2367; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2367; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3265; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3061; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3387; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3387; total time=   1.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3714; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3224; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2367; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2367; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2285; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2693; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2244; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2244; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2040; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2244; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2408; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3714; total time=   4.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3714; total time=   4.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3265; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3265; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3836; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3959; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3959; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3142; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2938; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2857; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3387; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3387; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2081; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2530; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2530; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2326; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2448; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2448; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2571; total time=   1.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3469; total time=   4.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2367; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2367; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3265; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=7, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3061; total time=   3.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3387; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3714; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=4, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3714; total time=   3.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=3224; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2367; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=4, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2285; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2693; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=7, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2693; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=5, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2244; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2040; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2244; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2408; total time=   3.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=13, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2408; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3714; total time=   4.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2326; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3265; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3836; total time=   5.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=None, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3836; total time=   5.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=3142; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2938; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=12, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=2938; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2857; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=3, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=7, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3387; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.013, gbrt_clf__max_depth=15, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2081; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2530; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2326; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.012, gbrt_clf__max_depth=9, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=2326; total time=   2.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2244; total time=   1.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2448; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3346; total time=   4.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2000; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2000; total time=   2.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3918; total time=   5.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=4000; total time=   2.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                           SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                          (&#x27;onehotencoder&#x27;,\n",
       "                                                                                           OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                transformers=[(&#x27;num&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                                SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                                               (&#x27;standardscaler&#x27;,\n",
       "                                                                                                StandardScaler()...\n",
       "                                        &#x27;gbrt_clf__max_features&#x27;: [&#x27;log2&#x27;,\n",
       "                                                                   &#x27;sqrt&#x27;],\n",
       "                                        &#x27;gbrt_clf__min_samples_leaf&#x27;: [4, 5, 6,\n",
       "                                                                       7, 8],\n",
       "                                        &#x27;gbrt_clf__min_samples_split&#x27;: [35, 38,\n",
       "                                                                        40, 42,\n",
       "                                                                        45],\n",
       "                                        &#x27;gbrt_clf__n_estimators&#x27;: [2000, 2040,\n",
       "                                                                   2081, 2122,\n",
       "                                                                   2163, 2204,\n",
       "                                                                   2244, 2285,\n",
       "                                                                   2326, 2367,\n",
       "                                                                   2408, 2448,\n",
       "                                                                   2489, 2530,\n",
       "                                                                   2571, 2612,\n",
       "                                                                   2653, 2693,\n",
       "                                                                   2734, 2775,\n",
       "                                                                   2816, 2857,\n",
       "                                                                   2897, 2938,\n",
       "                                                                   2979, 3020,\n",
       "                                                                   3061, 3102,\n",
       "                                                                   3142, 3183, ...]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-122\" type=\"checkbox\" ><label for=\"sk-estimator-id-122\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                           SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                          (&#x27;onehotencoder&#x27;,\n",
       "                                                                                           OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                transformers=[(&#x27;num&#x27;,\n",
       "                                                                               Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                                                SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                                               (&#x27;standardscaler&#x27;,\n",
       "                                                                                                StandardScaler()...\n",
       "                                        &#x27;gbrt_clf__max_features&#x27;: [&#x27;log2&#x27;,\n",
       "                                                                   &#x27;sqrt&#x27;],\n",
       "                                        &#x27;gbrt_clf__min_samples_leaf&#x27;: [4, 5, 6,\n",
       "                                                                       7, 8],\n",
       "                                        &#x27;gbrt_clf__min_samples_split&#x27;: [35, 38,\n",
       "                                                                        40, 42,\n",
       "                                                                        45],\n",
       "                                        &#x27;gbrt_clf__n_estimators&#x27;: [2000, 2040,\n",
       "                                                                   2081, 2122,\n",
       "                                                                   2163, 2204,\n",
       "                                                                   2244, 2285,\n",
       "                                                                   2326, 2367,\n",
       "                                                                   2408, 2448,\n",
       "                                                                   2489, 2530,\n",
       "                                                                   2571, 2612,\n",
       "                                                                   2653, 2693,\n",
       "                                                                   2734, 2775,\n",
       "                                                                   2816, 2857,\n",
       "                                                                   2897, 2938,\n",
       "                                                                   2979, 3020,\n",
       "                                                                   3061, 3102,\n",
       "                                                                   3142, 3183, ...]},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-123\" type=\"checkbox\" ><label for=\"sk-estimator-id-123\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                              SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                             (&#x27;onehotencoder&#x27;,\n",
       "                                                              OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                   transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;standardscaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;Fare&#x27;, &#x27;Age&#x27;])])),\n",
       "                (&#x27;gbrt_clf&#x27;, GradientBoostingClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-124\" type=\"checkbox\" ><label for=\"sk-estimator-id-124\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                             SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                            (&#x27;onehotencoder&#x27;,\n",
       "                                             OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                  transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;Fare&#x27;, &#x27;Age&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-125\" type=\"checkbox\" ><label for=\"sk-estimator-id-125\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Fare&#x27;, &#x27;Age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-126\" type=\"checkbox\" ><label for=\"sk-estimator-id-126\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-127\" type=\"checkbox\" ><label for=\"sk-estimator-id-127\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-128\" type=\"checkbox\" ><label for=\"sk-estimator-id-128\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Pclass&#x27;, &#x27;Sex&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;, &#x27;Embarked&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-129\" type=\"checkbox\" ><label for=\"sk-estimator-id-129\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-130\" type=\"checkbox\" ><label for=\"sk-estimator-id-130\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-131\" type=\"checkbox\" ><label for=\"sk-estimator-id-131\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('preprocessing',\n",
       "                                              ColumnTransformer(remainder=Pipeline(steps=[('simpleimputer',\n",
       "                                                                                           SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                          ('onehotencoder',\n",
       "                                                                                           OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                transformers=[('num',\n",
       "                                                                               Pipeline(steps=[('simpleimputer',\n",
       "                                                                                                SimpleImputer(strategy='median')),\n",
       "                                                                                               ('standardscaler',\n",
       "                                                                                                StandardScaler()...\n",
       "                                        'gbrt_clf__max_features': ['log2',\n",
       "                                                                   'sqrt'],\n",
       "                                        'gbrt_clf__min_samples_leaf': [4, 5, 6,\n",
       "                                                                       7, 8],\n",
       "                                        'gbrt_clf__min_samples_split': [35, 38,\n",
       "                                                                        40, 42,\n",
       "                                                                        45],\n",
       "                                        'gbrt_clf__n_estimators': [2000, 2040,\n",
       "                                                                   2081, 2122,\n",
       "                                                                   2163, 2204,\n",
       "                                                                   2244, 2285,\n",
       "                                                                   2326, 2367,\n",
       "                                                                   2408, 2448,\n",
       "                                                                   2489, 2530,\n",
       "                                                                   2571, 2612,\n",
       "                                                                   2653, 2693,\n",
       "                                                                   2734, 2775,\n",
       "                                                                   2816, 2857,\n",
       "                                                                   2897, 2938,\n",
       "                                                                   2979, 3020,\n",
       "                                                                   3061, 3102,\n",
       "                                                                   3142, 3183, ...]},\n",
       "                   random_state=42, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "# Define the hyperparameter space\n",
    "n_estimators = [int(x) for x in np.linspace(start = 2000, stop = 4000, num = 50)]\n",
    "learning_rate = [0.012, 0.0125, 0.013, 0.0135, 0.014]\n",
    "max_features = ['log2', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(2, 15, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [35, 38, 40, 42, 45]\n",
    "min_samples_leaf = [4, 5, 6, 7, 8]\n",
    "\n",
    "random_grid = {\n",
    "    'gbrt_clf__n_estimators': n_estimators,\n",
    "    'gbrt_clf__max_features': max_features,\n",
    "    'gbrt_clf__learning_rate': learning_rate,\n",
    "    'gbrt_clf__max_depth': max_depth,\n",
    "    'gbrt_clf__min_samples_split': min_samples_split,\n",
    "    'gbrt_clf__min_samples_leaf': min_samples_leaf,\n",
    "}\n",
    "\n",
    "pipe_gbrt = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"gbrt_clf\", GradientBoostingClassifier(random_state=42)),\n",
    "])\n",
    "\n",
    "gbrt_random = RandomizedSearchCV(\n",
    "    pipe_gbrt, param_distributions=random_grid, n_iter=200, cv=5,\n",
    "    scoring='accuracy', random_state=42, n_jobs=-1, verbose=2)\n",
    "\n",
    "\n",
    "gbrt_random.fit(titanic, titanic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "41c75db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gbrt_clf__n_estimators': 2204, 'gbrt_clf__min_samples_split': 40, 'gbrt_clf__min_samples_leaf': 4, 'gbrt_clf__max_features': 'sqrt', 'gbrt_clf__max_depth': 3, 'gbrt_clf__learning_rate': 0.014}\n"
     ]
    }
   ],
   "source": [
    "print(gbrt_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "48db39f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8876404494382022"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=4000; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2163; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3346; total time=   2.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3346; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3346; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2244; total time=   0.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2448; total time=   2.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3346; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3346; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3918; total time=   5.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3918; total time=   5.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2163; total time=   1.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3346; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3346; total time=   3.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2081; total time=   2.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2081; total time=   2.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2244; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=2, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=6, gbrt_clf__min_samples_split=42, gbrt_clf__n_estimators=2244; total time=   1.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=38, gbrt_clf__n_estimators=2448; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3346; total time=   3.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2000; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2000; total time=   2.8s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3918; total time=   4.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=4000; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=4000; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2163; total time=   1.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3346; total time=   3.9s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3346; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2081; total time=   2.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2081; total time=   2.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=40, gbrt_clf__n_estimators=3346; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=15, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2000; total time=   3.2s\n",
      "[CV] END gbrt_clf__learning_rate=0.0135, gbrt_clf__max_depth=13, gbrt_clf__max_features=log2, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=3918; total time=   5.3s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=5, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=4000; total time=   2.7s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2163; total time=   1.5s\n",
      "[CV] END gbrt_clf__learning_rate=0.0125, gbrt_clf__max_depth=3, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2163; total time=   1.4s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=12, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3346; total time=   4.0s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3346; total time=   3.6s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=8, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=4, gbrt_clf__min_samples_split=45, gbrt_clf__n_estimators=3346; total time=   3.1s\n",
      "[CV] END gbrt_clf__learning_rate=0.014, gbrt_clf__max_depth=11, gbrt_clf__max_features=sqrt, gbrt_clf__min_samples_leaf=8, gbrt_clf__min_samples_split=35, gbrt_clf__n_estimators=2081; total time=   2.3s\n"
     ]
    }
   ],
   "source": [
    "gbrt_random.best_estimator_.score(titanic, titanic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cf8f77",
   "metadata": {},
   "source": [
    "Best GBC hyperparameters found after 200 iterations:\n",
    "\n",
    "{'gbrt_clf__n_estimators': 2089, 'gbrt_clf__min_samples_split': 25, 'gbrt_clf__min_samples_leaf': 5, 'gbrt_clf__max_features': 'sqrt', 'gbrt_clf__max_depth': 4, 'gbrt_clf__learning_rate': 0.01}\n",
    "\n",
    "Reaches 90,9% Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5b1f3f",
   "metadata": {},
   "source": [
    "# Evaluate Best Performing Model on Test Set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca0ab40",
   "metadata": {},
   "source": [
    "Now we will be evaluating the best performing model (the Gradient Boost Classifier) against our separated test set and later we will generating predictions to rank on Kaggle. \n",
    "\n",
    "First we prepare the separated test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bfee6f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test = strat_test_set.drop(\"Survived\", axis=1, inplace=False)\n",
    "titanic_test_labels = strat_test_set[\"Survived\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44523d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Int64Index: 179 entries, 226 to 235\n",
      "Series name: Survived\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "179 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 2.8 KB\n"
     ]
    }
   ],
   "source": [
    "titanic_test_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7076eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179 entries, 226 to 235\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    179 non-null    int64  \n",
      " 1   Sex       179 non-null    object \n",
      " 2   Age       136 non-null    float64\n",
      " 3   SibSp     179 non-null    int64  \n",
      " 4   Parch     179 non-null    int64  \n",
      " 5   Fare      179 non-null    float64\n",
      " 6   Embarked  179 non-null    object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 11.2+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "730e63b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9776536312849162"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "pipe_gbrt = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"gbrt_clf\", GradientBoostingClassifier(n_estimators=2089, min_samples_split=25, min_samples_leaf=5,\n",
    "                                            max_features='sqrt', max_depth=4, learning_rate=0.01,\n",
    "                                            random_state=42)),\n",
    "])\n",
    "\n",
    "pipe_gbrt.fit(titanic_test, titanic_test_labels)\n",
    "\n",
    "pipe_gbrt.score(titanic_test, titanic_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e960e7b8",
   "metadata": {},
   "source": [
    "Whaaaaat? We get whoooping 97,8% accuracy on the test set? That is nuts and even unexpected, but still good news. We well proceed to do some predictions now for Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308370be",
   "metadata": {},
   "source": [
    "# Creating Submissions for Kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "07c11ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_sub = pd.read_csv(Path(\"datasets/titanic/test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2bacbba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing submission file: filling Passenger IDs\n",
    "\n",
    "submission = titanic_sub['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ada0b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping not used features during training. Preparing test set to apply our model and \n",
    "# output predictions for submission\n",
    "titanic_sub_prepared = titanic_sub.drop(columns=['PassengerId','Name','Ticket', 'Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2649b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using our best model to create submission predictions on test set\n",
    "y_sub_test_pred = pipe_gbrt.predict(titanic_sub_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d4c9f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding predictions to our submission file\n",
    "submission = pd.DataFrame(submission)\n",
    "\n",
    "submission['Survived'] = y_sub_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "11f71a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating submission CSV file with our predictions and passenger IDs  \n",
    "\n",
    "filepath = Path('submission/submission.csv')  \n",
    "\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "\n",
    "submission.to_csv(filepath, index=False)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
